{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ì²« ë²ˆì§¸ ì‹œë„"
      ],
      "metadata": {
        "id": "0ylYDIh1kQC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- í˜„ì¬ ë°ì´í„° êµ¬ì¡° = 1ìºë¦­í„°ë‹¹ ì—¬ëŸ¬ ì¥ë¹„ í–‰\n",
        "- 1í–‰ 1ìºë¦­í„° êµ¬ì¡°ë¡œ ë°”ê¾¸ëŠ” ê²ƒì´ ë‹¤ì†Œ ì–´ë ¤ì›Œì„œ, ë¨¸ì‹ ëŸ¬ë‹ ëŒ€ì‹  ë”¥ëŸ¬ë‹ ì´ìš©í•  ì˜ˆì •"
      ],
      "metadata": {
        "id": "HIfxOoJPS4Ls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqx1fi4zFx8C"
      },
      "outputs": [],
      "source": [
        "# 'None' ë¬¸ìì—´ì´ ê²°ì¸¡ì¹˜ë¡œ ì˜¤í•´ë°›ì§€ ì•Šë„ë¡ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/item_nomissingvalues_copy.csv', na_values=[], keep_default_na=False)\n",
        "\n",
        "# ì „íˆ¬ë ¥ ì§€í‘œ í¬í•¨í•˜ê³  ìˆëŠ” ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "df_stat = pd.read_csv('/content/drive/MyDrive/data/merged/stat_merged.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dfì™€ df_statì˜ 'ì „íˆ¬ë ¥' ì¹¼ëŸ¼ ë³‘í•©\n",
        "\n",
        "# 1. ë³‘í•© ëŒ€ìƒ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ (ì¤‘ë³µ ì œê±° í¬í•¨)\n",
        "df_stat_trimmed = df_stat[['nickname', 'subclass', 'ì „íˆ¬ë ¥']].drop_duplicates()\n",
        "\n",
        "# 2. left joinìœ¼ë¡œ 'ì „íˆ¬ë ¥' ì¶”ê°€\n",
        "df = df.merge(df_stat_trimmed, on=['nickname', 'subclass'], how='left')\n",
        "\n",
        "# 3. ì „íˆ¬ë ¥ ê²°ì¸¡ì¹˜ ì œê±°\n",
        "df.dropna(subset=['ì „íˆ¬ë ¥'], inplace=True)"
      ],
      "metadata": {
        "id": "tgmwZ1O_GJhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AKl4-RYGM0p",
        "outputId": "4f638f05-17a1-4d57-ffd0-cc47901b3570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1059756 entries, 0 to 1063723\n",
            "Data columns (total 38 columns):\n",
            " #   Column                               Non-Null Count    Dtype  \n",
            "---  ------                               --------------    -----  \n",
            " 0   nickname                             1059756 non-null  object \n",
            " 1   subclass                             1059756 non-null  object \n",
            " 2   equipment_slot                       1059756 non-null  object \n",
            " 3   item_name                            1059756 non-null  object \n",
            " 4   boss_damage_total                    1059756 non-null  int64  \n",
            " 5   ignore_monster_armor_total           1059756 non-null  int64  \n",
            " 6   all_stat_total                       1059756 non-null  int64  \n",
            " 7   damage_total                         1059756 non-null  int64  \n",
            " 8   potential_option_grade               1059756 non-null  object \n",
            " 9   additional_potential_option_grade    1059756 non-null  object \n",
            " 10  exceptional_upgrade                  1059756 non-null  bool   \n",
            " 11  boss_damage_add                      1059756 non-null  int64  \n",
            " 12  damage_add                           1059756 non-null  int64  \n",
            " 13  all_stat_add                         1059756 non-null  int64  \n",
            " 14  starforce                            1059756 non-null  int64  \n",
            " 15  starforce_scroll_flag                1059756 non-null  object \n",
            " 16  special_ring_level                   1059756 non-null  int64  \n",
            " 17  main_stat_type                       1059756 non-null  object \n",
            " 18  bonus_stat_total                     1059756 non-null  int64  \n",
            " 19  mainstat_total                       1059756 non-null  float64\n",
            " 20  power_total                          1059756 non-null  float64\n",
            " 21  potential_option_1_grade             1059756 non-null  object \n",
            " 22  potential_option_2_grade             1059756 non-null  object \n",
            " 23  potential_option_3_grade             1059756 non-null  object \n",
            " 24  main_pot_grade_summary               1059756 non-null  object \n",
            " 25  additional_potential_option_1_grade  1059756 non-null  object \n",
            " 26  additional_potential_option_2_grade  1059756 non-null  object \n",
            " 27  additional_potential_option_3_grade  1059756 non-null  object \n",
            " 28  add_pot_grade_summary                1059756 non-null  object \n",
            " 29  mainstat_add                         1059756 non-null  float64\n",
            " 30  power_add                            1059756 non-null  float64\n",
            " 31  mainstat_etc                         1059756 non-null  float64\n",
            " 32  power_etc                            1059756 non-null  int64  \n",
            " 33  mainstat_starforce                   1059756 non-null  float64\n",
            " 34  power_starforce                      1059756 non-null  int64  \n",
            " 35  potential_status                     1059756 non-null  object \n",
            " 36  item_group                           1059756 non-null  object \n",
            " 37  ì „íˆ¬ë ¥                                  1059756 non-null  float64\n",
            "dtypes: bool(1), float64(7), int64(12), object(18)\n",
            "memory usage: 308.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import torch\n",
        "\n",
        "# ì „ì²˜ë¦¬ êµ¬ì„±\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "# Label encoding\n",
        "encoders = {col: LabelEncoder().fit(df[col]) for col in cat_cols}\n",
        "for col, encoder in encoders.items():\n",
        "    df[col] = encoder.transform(df[col])\n",
        "\n",
        "# ìˆ˜ì¹˜í˜• ì •ê·œí™”\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])"
      ],
      "metadata": {
        "id": "N4VQueJeVOAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì¥ë¹„ ì‹œí€€ìŠ¤ ë§Œë“¤ê¸°\n",
        "feature_cols = cat_cols + num_cols\n",
        "feature_dim = len(feature_cols)\n",
        "max_len = 24  # ìµœëŒ€ ì¥ë¹„ ìˆ˜\n",
        "\n",
        "character_inputs = []\n",
        "character_labels = []\n",
        "attention_masks = []  # ë§ˆìŠ¤í¬ ì¶”ê°€\n",
        "\n",
        "for name, group in df.groupby('nickname'):\n",
        "    features = group[feature_cols].values\n",
        "    valid_len = len(features)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        pad = np.zeros((max_len - valid_len, feature_dim))\n",
        "        features = np.vstack([features, pad])\n",
        "        mask = [1] * valid_len + [0] * (max_len - valid_len)\n",
        "    else:\n",
        "        features = features[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    character_inputs.append(torch.tensor(features, dtype=torch.float32))\n",
        "    attention_masks.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    character_labels.append(group['ì „íˆ¬ë ¥'].iloc[0])"
      ],
      "metadata": {
        "id": "i2LA1gSKVN9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor ë³€í™˜\n",
        "X = torch.stack(character_inputs)          # (B, T, D)\n",
        "mask = torch.stack(attention_masks)        # (B, T)\n",
        "y = torch.tensor(character_labels)         # (B,)"
      ],
      "metadata": {
        "id": "_9sGYc06VN4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ ì •ì˜\n",
        "import torch.nn as nn\n",
        "\n",
        "class DeepSetMasked(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, mask):  # x: (B, T, D), mask: (B, T)\n",
        "        encoded = self.phi(x)  # (B, T, H)\n",
        "        masked_encoded = encoded * mask.unsqueeze(-1)  # mask í™•ì¥ í›„ ê³±í•˜ê¸°\n",
        "        aggregated = masked_encoded.sum(dim=1)  # (B, H)\n",
        "        return self.rho(aggregated).squeeze()  # (B,)"
      ],
      "metadata": {
        "id": "VMlwb-BTVNw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader ë§Œë“¤ê¸°\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "dataset = TensorDataset(X, mask, y)\n",
        "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "dmvB1_PJVNqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í•™ìŠµ ë£¨í”„\n",
        "model = DeepSetMasked(input_dim=X.shape[-1]).to(\"cuda\")\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for xb, mb, yb in train_loader:\n",
        "        xb = xb.to(\"cuda\")\n",
        "        mb = mb.to(\"cuda\")\n",
        "        yb = yb.to(\"cuda\").float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb, mb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item() * len(xb)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} - Loss: {epoch_loss / len(dataset):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGCir_2dbBBN",
        "outputId": "c37e9658-1365-4172-fb67-5e62a1db8983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss: 20313777141531684.0000\n",
            "Epoch 2 - Loss: 10104777078699980.0000\n",
            "Epoch 3 - Loss: 9557737416839084.0000\n",
            "Epoch 4 - Loss: 8866219926050771.0000\n",
            "Epoch 5 - Loss: 7874012985708706.0000\n",
            "Epoch 6 - Loss: 6750520516183836.0000\n",
            "Epoch 7 - Loss: 6049198103661723.0000\n",
            "Epoch 8 - Loss: 5757279609114496.0000\n",
            "Epoch 9 - Loss: 5630692330944702.0000\n",
            "Epoch 10 - Loss: 5557885620930596.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(X.to(\"cuda\"), mask.to(\"cuda\")).cpu().numpy()\n",
        "    y_true = y.cpu().numpy()"
      ],
      "metadata": {
        "id": "U3YecKmLbA8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "mse = mean_squared_error(y_true, preds)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_true, preds)\n",
        "\n",
        "print(f\"RMSE: {rmse:,.0f}\")\n",
        "print(f\"RÂ²: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw4qM8G5bA5K",
        "outputId": "4bc0142e-4e00-40da-f88d-9819b3b7738f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 74,356,325\n",
            "RÂ²: 0.4940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ë‘ ë²ˆì§¸ ì‹œë„"
      ],
      "metadata": {
        "id": "ljjWGfd4j-Ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'None' ë¬¸ìì—´ì´ ê²°ì¸¡ì¹˜ë¡œ ì˜¤í•´ë°›ì§€ ì•Šë„ë¡ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/item_nomissingvalues_copy.csv', na_values=[], keep_default_na=False)\n",
        "\n",
        "# ì „íˆ¬ë ¥ ì§€í‘œ í¬í•¨í•˜ê³  ìˆëŠ” ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "df_stat = pd.read_csv('/content/drive/MyDrive/data/merged/stat_merged.csv')"
      ],
      "metadata": {
        "id": "4vagse7ckLPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dfì™€ df_statì˜ 'ì „íˆ¬ë ¥' ì¹¼ëŸ¼ ë³‘í•©\n",
        "\n",
        "# 1. ë³‘í•© ëŒ€ìƒ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ (ì¤‘ë³µ ì œê±° í¬í•¨)\n",
        "df_stat_trimmed = df_stat[['nickname', 'subclass', 'ì „íˆ¬ë ¥']].drop_duplicates()\n",
        "\n",
        "# 2. left joinìœ¼ë¡œ 'ì „íˆ¬ë ¥' ì¶”ê°€\n",
        "df = df.merge(df_stat_trimmed, on=['nickname', 'subclass'], how='left')\n",
        "\n",
        "# 3. ì „íˆ¬ë ¥ ê²°ì¸¡ì¹˜ ì œê±°\n",
        "df.dropna(subset=['ì „íˆ¬ë ¥'], inplace=True)"
      ],
      "metadata": {
        "id": "1gtBCom0kTZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# ëŒ€ìƒ ì—´\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ê°„ë‹¨íˆ dropna)\n",
        "df = df.dropna(subset=cat_cols + num_cols + ['ì „íˆ¬ë ¥'])\n",
        "\n",
        "# ë²”ì£¼í˜• ì¸ì½”ë”©\n",
        "encoders = {}\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    encoders[col] = le\n",
        "\n",
        "# ìˆ˜ì¹˜í˜• ì •ê·œí™”\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "\n",
        "# log ë³€í™˜\n",
        "df['log_ì „íˆ¬ë ¥'] = np.log1p(df['ì „íˆ¬ë ¥'])"
      ],
      "metadata": {
        "id": "kxzmsGa9bA2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch import nn\n",
        "\n",
        "# === 1. ì „ì²˜ë¦¬ êµ¬ì„± ===\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "existing_cat_cols = [col for col in cat_cols if col in df.columns]\n",
        "existing_num_cols = [col for col in num_cols if col in df.columns]\n",
        "target_col = 'ì „íˆ¬ë ¥'\n",
        "\n",
        "df = df.dropna(subset=existing_cat_cols + existing_num_cols + [target_col])\n",
        "\n",
        "# ì¸ì½”ë”© + ì •ê·œí™”\n",
        "for col in existing_cat_cols:\n",
        "    df[col] = LabelEncoder().fit_transform(df[col])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[existing_num_cols] = scaler.fit_transform(df[existing_num_cols])\n",
        "\n",
        "df['log_ì „íˆ¬ë ¥'] = np.log1p(df[target_col])\n",
        "\n",
        "# === 2. ë°ì´í„° ì¤€ë¹„ ===\n",
        "X = torch.tensor(df[existing_cat_cols + existing_num_cols].values, dtype=torch.float32)\n",
        "y = torch.tensor(df['log_ì „íˆ¬ë ¥'].values, dtype=torch.float32)\n",
        "\n",
        "dataset = TensorDataset(X, y)\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# === 3. ëª¨ë¸ ì •ì˜ ===\n",
        "class SimpleRegressor(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x).squeeze()\n",
        "\n",
        "model = SimpleRegressor(X.shape[1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# === 4. í•™ìŠµ ===\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for xb, yb in loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * len(xb)\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(dataset):.4f}\")\n",
        "\n",
        "# === 5. í‰ê°€ ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X).numpy()\n",
        "    y_true = y.numpy()\n",
        "    y_pred_exp = np.expm1(y_pred)\n",
        "    y_true_exp = np.expm1(y_true)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_true_exp, y_pred_exp))\n",
        "r2 = r2_score(y_true_exp, y_pred_exp)\n",
        "\n",
        "print(f\"ğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼\")\n",
        "print(f\"RMSE: {rmse:,.0f}\")\n",
        "print(f\"RÂ²: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rsU4Yb-bA0n",
        "outputId": "b0140033-e448-4e2a-ee46-1dd42aaa251a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 1.3431\n",
            "Epoch 2: Loss = 0.9169\n",
            "Epoch 3: Loss = 0.9009\n",
            "Epoch 4: Loss = 0.8930\n",
            "Epoch 5: Loss = 0.8864\n",
            "Epoch 6: Loss = 0.8815\n",
            "Epoch 7: Loss = 0.8775\n",
            "Epoch 8: Loss = 0.8762\n",
            "Epoch 9: Loss = 0.8728\n",
            "Epoch 10: Loss = 0.8708\n",
            "ğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼\n",
            "RMSE: 89,449,549\n",
            "RÂ²: 0.2594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì„¸ ë²ˆì§¸ ì‹œë„"
      ],
      "metadata": {
        "id": "Tcf6yBLvnUzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Masked DeepSetsë¡œ ì‹œí€€ìŠ¤ í•™ìŠµ\n",
        "\n",
        "# (1) ë°ì´í„° ì „ì²˜ë¦¬\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# ì‚¬ìš©í•  ë²”ì£¼í˜• / ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì •ì˜\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "# ì¡´ì¬í•˜ëŠ” ì—´ë§Œ í•„í„°ë§\n",
        "cat_cols = [col for col in cat_cols if col in df.columns]\n",
        "num_cols = [col for col in num_cols if col in df.columns]\n",
        "\n",
        "# ì „íˆ¬ë ¥ ìœ íš¨ì„± í™•ì¸\n",
        "if 'ì „íˆ¬ë ¥' not in df.columns:\n",
        "    raise ValueError(\"âŒ 'ì „íˆ¬ë ¥' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# ê²°ì¸¡ì¹˜ ì œê±°\n",
        "df = df.dropna(subset=cat_cols + num_cols + ['ì „íˆ¬ë ¥'])\n",
        "\n",
        "# ë²”ì£¼í˜• ì¸ì½”ë”©\n",
        "encoders = {}\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    encoders[col] = le\n",
        "\n",
        "# ìˆ˜ì¹˜í˜• ì •ê·œí™”\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "\n",
        "# ì „íˆ¬ë ¥ ë¡œê·¸ ë³€í™˜ (ì¶”í›„ ì„ íƒì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥)\n",
        "df['log_ì „íˆ¬ë ¥'] = np.log1p(df['ì „íˆ¬ë ¥'])"
      ],
      "metadata": {
        "id": "DafeZ4yEbAvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (2) ìºë¦­í„°ë³„ ì¥ë¹„ ì‹œí€€ìŠ¤ êµ¬ì„±(nickname ê¸°ì¤€ groupby)\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "feature_cols = cat_cols + num_cols\n",
        "feature_dim = len(feature_cols)\n",
        "max_len = 24  # ìºë¦­í„°ë‹¹ ìµœëŒ€ ì¥ë¹„ ìˆ˜\n",
        "\n",
        "character_inputs = []\n",
        "character_labels = []\n",
        "attention_masks = []\n",
        "\n",
        "for name, group in df.groupby('nickname'):\n",
        "    features = group[feature_cols].values\n",
        "    valid_len = len(features)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        pad = np.zeros((max_len - valid_len, feature_dim))\n",
        "        features = np.vstack([features, pad])\n",
        "        mask = [1] * valid_len + [0] * (max_len - valid_len)\n",
        "    else:\n",
        "        features = features[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    character_inputs.append(torch.tensor(features, dtype=torch.float32))\n",
        "    attention_masks.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    character_labels.append(group['ì „íˆ¬ë ¥'].iloc[0])  # log_ì „íˆ¬ë ¥ìœ¼ë¡œ ë°”ê¿€ ìˆ˜ë„ ìˆìŒ\n",
        "\n",
        "X = torch.stack(character_inputs).float()                # (B, T, D)\n",
        "mask = torch.stack(attention_masks).float()              # (B, T)\n",
        "y = torch.tensor(character_labels, dtype=torch.float32)  # (B,)"
      ],
      "metadata": {
        "id": "iz8Gz2d3bAtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (3) Masked DeepSets ëª¨ë¸ ì •ì˜\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MaskedDeepSets(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # x: (B, T, D), mask: (B, T)\n",
        "        encoded = self.phi(x)                          # (B, T, 64)\n",
        "        masked = encoded * mask.unsqueeze(-1)          # (B, T, 64)\n",
        "        pooled = masked.sum(dim=1)                     # (B, 64)\n",
        "        return self.rho(pooled).squeeze()              # (B,)"
      ],
      "metadata": {
        "id": "Sd4noVWgbAq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# ë°ì´í„°ì…‹ ë° ë¡œë” êµ¬ì„±\n",
        "dataset = TensorDataset(X, mask, y)\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# ëª¨ë¸ ì´ˆê¸°í™”\n",
        "model = MaskedDeepSets(input_dim=X.shape[-1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# í•™ìŠµ\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for xb, mb, yb in loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb, mb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * len(xb)\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(dataset):.4f}\")\n",
        "\n",
        "# í‰ê°€\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(X, mask).numpy()\n",
        "    y_true = y.numpy()\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_true, preds))\n",
        "r2 = r2_score(y_true, preds)\n",
        "\n",
        "print(f\"\\nğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼:\")\n",
        "print(f\"RMSE: {rmse:,.0f}\")\n",
        "print(f\"RÂ²: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHVCrn-6bAkY",
        "outputId": "00c7cfdc-5522-41a2-885a-e97d4b8e8d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 21320032586292988.0000\n",
            "Epoch 2: Loss = 10198710239161158.0000\n",
            "Epoch 3: Loss = 9711300646582294.0000\n",
            "Epoch 4: Loss = 9142901835325022.0000\n",
            "Epoch 5: Loss = 8357941116880978.0000\n",
            "Epoch 6: Loss = 7326946706100004.0000\n",
            "Epoch 7: Loss = 6429572304124114.0000\n",
            "Epoch 8: Loss = 5940441267996914.0000\n",
            "Epoch 9: Loss = 5726394045816610.0000\n",
            "Epoch 10: Loss = 5622332282307216.0000\n",
            "\n",
            "ğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼:\n",
            "RMSE: 74,712,527\n",
            "RÂ²: 0.4891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ íŠœë‹ ì‹œë„ (1)\n",
        "# ë²”ì£¼í˜• Feature -> Embedding vectorë¡œ í‘œí˜„\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MaskedDeepSetsWithEmbedding(nn.Module):\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        # x_cat: (B, T, num_cat), x_cont: (B, T, num_cont), mask: (B, T)\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        emb_cat = torch.cat(embs, dim=-1)  # (B, T, total_emb_dim)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)  # (B, T, input_dim)\n",
        "\n",
        "        encoded = self.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "        return self.rho(pooled).squeeze()"
      ],
      "metadata": {
        "id": "H7RSziSIqh9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ì…ë ¥ ë¶„ë¦¬ ë° í…ì„œ ìƒì„±\n",
        "\n",
        "# 1. embedding ì •ë³´ êµ¬ì„± (ê° ë²”ì£¼í˜• ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ ê°œìˆ˜)\n",
        "embedding_info = {col: df[col].nunique() for col in cat_cols}\n",
        "\n",
        "# 2. feature ë¶„ë¦¬\n",
        "feature_cols = cat_cols + num_cols\n",
        "feature_dim = len(feature_cols)\n",
        "max_len = 24\n",
        "\n",
        "x_cat_list = []\n",
        "x_cont_list = []\n",
        "attention_masks = []\n",
        "character_labels = []\n",
        "\n",
        "for name, group in df.groupby('nickname'):\n",
        "    cat_feats = group[cat_cols].values.astype(np.int64)  # long íƒ€ì…ìœ¼ë¡œ ë³€í™˜\n",
        "    cont_feats = group[num_cols].values.astype(np.float32)\n",
        "    valid_len = len(group)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        pad_cat = np.zeros((max_len - valid_len, len(cat_cols)), dtype=np.int64)\n",
        "        pad_cont = np.zeros((max_len - valid_len, len(num_cols)), dtype=np.float32)\n",
        "        cat_feats = np.vstack([cat_feats, pad_cat])\n",
        "        cont_feats = np.vstack([cont_feats, pad_cont])\n",
        "        mask = [1] * valid_len + [0] * (max_len - valid_len)\n",
        "    else:\n",
        "        cat_feats = cat_feats[:max_len]\n",
        "        cont_feats = cont_feats[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    x_cat_list.append(torch.tensor(cat_feats, dtype=torch.long))\n",
        "    x_cont_list.append(torch.tensor(cont_feats, dtype=torch.float32))\n",
        "    attention_masks.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    character_labels.append(group['ì „íˆ¬ë ¥'].iloc[0])  # log_ì „íˆ¬ë ¥ìœ¼ë¡œ ë°”ê¿”ë„ ë¨\n",
        "\n",
        "# í…ì„œí™”\n",
        "x_cat = torch.stack(x_cat_list)       # (B, T, num_cat)\n",
        "x_cont = torch.stack(x_cont_list)     # (B, T, num_cont)\n",
        "mask = torch.stack(attention_masks)   # (B, T)\n",
        "y = torch.tensor(character_labels, dtype=torch.float32)  # (B,)\n",
        "\n",
        "# í™•ì¸\n",
        "x_cat.shape, x_cont.shape, mask.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnUm6VVXq1A9",
        "outputId": "ec539c0d-b1da-4365-844c-5721827ee205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([45770, 24, 10]),\n",
              " torch.Size([45770, 24, 18]),\n",
              " torch.Size([45770, 24]),\n",
              " torch.Size([45770]))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding ëª¨ë¸ í•™ìŠµ ë£¨í”„ + í‰ê°€ ì½”ë“œ\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# ë°ì´í„°ì…‹ ë° DataLoader ìƒì„±\n",
        "dataset = TensorDataset(x_cat, x_cont, mask, y)\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# ëª¨ë¸ ì´ˆê¸°í™”\n",
        "model = MaskedDeepSetsWithEmbedding(embedding_info, num_cont_features=x_cont.shape[-1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# í•™ìŠµ\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for xcb, xfb, mb, yb in loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xcb, xfb, mb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * len(xcb)\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(dataset):.4f}\")\n",
        "\n",
        "# í‰ê°€\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(x_cat, x_cont, mask).numpy()\n",
        "    y_true = y.numpy()\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_true, preds))\n",
        "r2 = r2_score(y_true, preds)\n",
        "\n",
        "print(f\"\\nğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼:\")\n",
        "print(f\"RMSE: {rmse:,.0f}\")\n",
        "print(f\"RÂ²: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlMN4oFLrsrs",
        "outputId": "320466c8-384b-4b26-9e75-82fd3c349d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 19354970680136156.0000\n",
            "Epoch 2: Loss = 6985824516823240.0000\n",
            "Epoch 3: Loss = 5738621470542747.0000\n",
            "Epoch 4: Loss = 5513033042183031.0000\n",
            "Epoch 5: Loss = 5432516061833051.0000\n",
            "Epoch 6: Loss = 5383590933385174.0000\n",
            "Epoch 7: Loss = 5341979742175306.0000\n",
            "Epoch 8: Loss = 5311223582819306.0000\n",
            "Epoch 9: Loss = 5291353764650500.0000\n",
            "Epoch 10: Loss = 5272607709977308.0000\n",
            "\n",
            "ğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼:\n",
            "RMSE: 72,540,977\n",
            "RÂ²: 0.5184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ë„¤ ë²ˆì§¸ ì‹œë„"
      ],
      "metadata": {
        "id": "D5pbME5wu2mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# ì „ì²˜ë¦¬ êµ¬ì„±\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "df = df.dropna(subset=cat_cols + num_cols + ['ì „íˆ¬ë ¥'])\n",
        "\n",
        "encoders = {col: LabelEncoder().fit(df[col]) for col in cat_cols}\n",
        "for col in cat_cols:\n",
        "    df[col] = encoders[col].transform(df[col])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "\n",
        "# log ì „íˆ¬ë ¥ìœ¼ë¡œ ë°”ê¾¸ê¸°\n",
        "df['log_ì „íˆ¬ë ¥'] = np.log1p(df['ì „íˆ¬ë ¥'])"
      ],
      "metadata": {
        "id": "KfjZDipEsPSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì‹œí€€ìŠ¤ êµ¬ì„±\n",
        "import torch\n",
        "\n",
        "max_len = 24\n",
        "feature_dim = len(cat_cols + num_cols)\n",
        "x_cat_list, x_cont_list, mask_list, y_list = [], [], [], []\n",
        "\n",
        "for name, group in df.groupby('nickname'):\n",
        "    cat_feats = group[cat_cols].values.astype(np.int64)\n",
        "    cont_feats = group[num_cols].values.astype(np.float32)\n",
        "    valid_len = len(group)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        cat_feats = np.vstack([cat_feats, np.zeros((max_len - valid_len, len(cat_cols)))])\n",
        "        cont_feats = np.vstack([cont_feats, np.zeros((max_len - valid_len, len(num_cols)))])\n",
        "        mask = [1] * valid_len + [0] * (max_len - valid_len)\n",
        "    else:\n",
        "        cat_feats = cat_feats[:max_len]\n",
        "        cont_feats = cont_feats[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    x_cat_list.append(torch.tensor(cat_feats, dtype=torch.long))\n",
        "    x_cont_list.append(torch.tensor(cont_feats, dtype=torch.float32))\n",
        "    mask_list.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    y_list.append(np.log1p(group['ì „íˆ¬ë ¥'].iloc[0]))  # log ì „íˆ¬ë ¥\n",
        "\n",
        "x_cat = torch.stack(x_cat_list)\n",
        "x_cont = torch.stack(x_cont_list)\n",
        "mask = torch.stack(mask_list)\n",
        "y = torch.tensor(y_list, dtype=torch.float32)\n",
        "\n",
        "embedding_info = {col: df[col].nunique() for col in cat_cols}"
      ],
      "metadata": {
        "id": "s2-6NogQvBy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ ì •ì˜\n",
        "import torch.nn as nn\n",
        "\n",
        "class MaskedDeepSetsWithEmbedding(nn.Module):\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1),\n",
        "            nn.Softplus()  # log ì˜ˆì¸¡ í­ì£¼ ë°©ì§€\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        emb_cat = torch.cat(embs, dim=-1)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        encoded = self.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "        return self.rho(pooled).squeeze()"
      ],
      "metadata": {
        "id": "OVkCM9mGvHK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í•™ìŠµ\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "dataset = TensorDataset(x_cat, x_cont, mask, y)\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "model = MaskedDeepSetsWithEmbedding(embedding_info, x_cont.shape[-1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for xcb, xfb, mb, yb in loader:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(xcb, xfb, mb)\n",
        "        loss = criterion(pred, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * len(xcb)\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(dataset):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9qQ3D3qvY6R",
        "outputId": "8833442c-64c1-4740-abb1-6a431e38a41a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 5.7401\n",
            "Epoch 2: Loss = 0.7835\n",
            "Epoch 3: Loss = 0.6542\n",
            "Epoch 4: Loss = 0.6242\n",
            "Epoch 5: Loss = 0.6122\n",
            "Epoch 6: Loss = 0.5977\n",
            "Epoch 7: Loss = 0.5904\n",
            "Epoch 8: Loss = 0.5796\n",
            "Epoch 9: Loss = 0.5688\n",
            "Epoch 10: Loss = 0.5471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í‰ê°€\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred_log = model(x_cat, x_cont, mask).numpy()\n",
        "    y_log = y.numpy()\n",
        "\n",
        "# ì•ˆì •ì„±: í´ë¦¬í•‘\n",
        "pred_log = np.clip(pred_log, 0, 50)\n",
        "y_log = np.clip(y_log, 0, 50)\n",
        "\n",
        "# ì „íˆ¬ë ¥ ë³µì›\n",
        "pred_real = np.expm1(pred_log)\n",
        "y_real = np.expm1(y_log)\n",
        "\n",
        "# ì§€í‘œ\n",
        "rmse = np.sqrt(mean_squared_error(y_real, pred_real))\n",
        "rmsle = np.sqrt(mean_squared_error(np.log1p(y_real), np.log1p(pred_real)))\n",
        "r2 = r2_score(y_real, pred_real)\n",
        "\n",
        "print(f\"ğŸ“Š í‰ê°€ ê²°ê³¼:\")\n",
        "print(f\"RMSE: {rmse:,.0f}\")\n",
        "print(f\"RMSLE: {rmsle:.4f}\")\n",
        "print(f\"RÂ²: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx4DLMDovcst",
        "outputId": "1b5e4b92-a67b-49a6-8dbb-f797cf3afd92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š í‰ê°€ ê²°ê³¼:\n",
            "RMSE: 73,975,112\n",
            "RMSLE: 0.7019\n",
            "RÂ²: 0.4992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ë‹¤ì„¯ ë²ˆì§¸ ì‹œë„"
      ],
      "metadata": {
        "id": "qDiG3M6bxKuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ì‹œë“œ ê³ ì •\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# 2. ì •ë ¬ ë³´ì¥ëœ groupby â†’ í…ì„œ êµ¬ì„±\n",
        "df = df.sort_values(\"nickname\")  # í•„ìˆ˜ ì •ë ¬\n",
        "\n",
        "# ì¥ë¹„ ìˆ˜ íŒŒìƒ í”¼ì²˜\n",
        "equip_counts = mask.sum(dim=1).unsqueeze(1).repeat(1, x_cont.shape[1]).unsqueeze(2)\n",
        "x_cont_with_count = torch.cat([x_cont, equip_counts], dim=2)\n",
        "\n",
        "# 3. ë”¥ëŸ¬ë‹ ëª¨ë¸ ì •ì˜\n",
        "class DeepMaskedModel(nn.Module):\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)  # Softplus ì œê±°: ì „íˆ¬ë ¥ ì§ì ‘ ì˜ˆì¸¡\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        emb_cat = torch.cat(embs, dim=-1)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        encoded = self.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "        return self.rho(pooled).squeeze()\n",
        "\n",
        "# 4. K-Fold í•™ìŠµ ë° í‰ê°€\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmses, r2s = [], []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(x_cat)):\n",
        "    print(f\"\\nğŸ“‚ Fold {fold + 1}\")\n",
        "\n",
        "    train_set = TensorDataset(x_cat[train_idx], x_cont_with_count[train_idx], mask[train_idx], y[train_idx])\n",
        "    val_set = TensorDataset(x_cat[val_idx], x_cont_with_count[val_idx], mask[val_idx], y[val_idx])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=256, shuffle=False)\n",
        "\n",
        "    model = DeepMaskedModel(embedding_info, x_cont_with_count.shape[-1])\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb, xfb, mb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader.dataset):.4f}\")\n",
        "\n",
        "    # Foldë³„ í‰ê°€\n",
        "    model.eval()\n",
        "    preds_all, y_all = [], []\n",
        "    with torch.no_grad():\n",
        "        for xcb, xfb, mb, yb in val_loader:\n",
        "            preds = model(xcb, xfb, mb)\n",
        "            preds_all.append(preds.numpy())\n",
        "            y_all.append(yb.numpy())\n",
        "\n",
        "    pred_all = np.concatenate(preds_all)\n",
        "    y_true = np.concatenate(y_all)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred_all))\n",
        "    r2 = r2_score(y_true, pred_all)\n",
        "    rmses.append(rmse)\n",
        "    r2s.append(r2)\n",
        "\n",
        "    print(f\"âœ… Fold {fold+1} RMSE: {rmse:,.2f}, RÂ²: {r2:.4f}\")\n",
        "\n",
        "# ìµœì¢… í‰ê·  ì¶œë ¥\n",
        "print(\"\\nğŸ¯ K-Fold í‰ê·  ì„±ëŠ¥:\")\n",
        "print(f\"Avg RMSE: {np.mean(rmses):,.2f}\")\n",
        "print(f\"Avg RÂ²: {np.mean(r2s):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBF8lY20xGMQ",
        "outputId": "54cf9eaa-fcc9-4f00-f95d-f58c73325104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“‚ Fold 1\n",
            "Epoch 1: Loss = 3.4886\n",
            "Epoch 2: Loss = 0.7343\n",
            "Epoch 3: Loss = 0.6853\n",
            "Epoch 4: Loss = 0.6459\n",
            "Epoch 5: Loss = 0.6000\n",
            "Epoch 6: Loss = 0.5665\n",
            "Epoch 7: Loss = 0.5513\n",
            "Epoch 8: Loss = 0.5325\n",
            "Epoch 9: Loss = 0.5008\n",
            "Epoch 10: Loss = 0.4938\n",
            "âœ… Fold 1 RMSE: 0.73, RÂ²: 0.6740\n",
            "\n",
            "ğŸ“‚ Fold 2\n",
            "Epoch 1: Loss = 4.0717\n",
            "Epoch 2: Loss = 0.7298\n",
            "Epoch 3: Loss = 0.6257\n",
            "Epoch 4: Loss = 0.5967\n",
            "Epoch 5: Loss = 0.5543\n",
            "Epoch 6: Loss = 0.5527\n",
            "Epoch 7: Loss = 0.5215\n",
            "Epoch 8: Loss = 0.5127\n",
            "Epoch 9: Loss = 0.4905\n",
            "Epoch 10: Loss = 0.4871\n",
            "âœ… Fold 2 RMSE: 0.71, RÂ²: 0.6544\n",
            "\n",
            "ğŸ“‚ Fold 3\n",
            "Epoch 1: Loss = 4.6613\n",
            "Epoch 2: Loss = 0.6714\n",
            "Epoch 3: Loss = 0.6011\n",
            "Epoch 4: Loss = 0.5780\n",
            "Epoch 5: Loss = 0.5465\n",
            "Epoch 6: Loss = 0.5278\n",
            "Epoch 7: Loss = 0.5015\n",
            "Epoch 8: Loss = 0.4608\n",
            "Epoch 9: Loss = 0.4540\n",
            "Epoch 10: Loss = 0.4435\n",
            "âœ… Fold 3 RMSE: 1.00, RÂ²: 0.4164\n",
            "\n",
            "ğŸ“‚ Fold 4\n",
            "Epoch 1: Loss = 4.8802\n",
            "Epoch 2: Loss = 0.7252\n",
            "Epoch 3: Loss = 0.6534\n",
            "Epoch 4: Loss = 0.6133\n",
            "Epoch 5: Loss = 0.5635\n",
            "Epoch 6: Loss = 0.5344\n",
            "Epoch 7: Loss = 0.5197\n",
            "Epoch 8: Loss = 0.5025\n",
            "Epoch 9: Loss = 0.4899\n",
            "Epoch 10: Loss = 0.4668\n",
            "âœ… Fold 4 RMSE: 0.81, RÂ²: 0.6442\n",
            "\n",
            "ğŸ“‚ Fold 5\n",
            "Epoch 1: Loss = 4.9042\n",
            "Epoch 2: Loss = 0.6916\n",
            "Epoch 3: Loss = 0.6190\n",
            "Epoch 4: Loss = 0.5996\n",
            "Epoch 5: Loss = 0.5719\n",
            "Epoch 6: Loss = 0.5604\n",
            "Epoch 7: Loss = 0.5315\n",
            "Epoch 8: Loss = 0.5102\n",
            "Epoch 9: Loss = 0.5027\n",
            "Epoch 10: Loss = 0.4902\n",
            "âœ… Fold 5 RMSE: 0.70, RÂ²: 0.7282\n",
            "\n",
            "ğŸ¯ K-Fold í‰ê·  ì„±ëŠ¥:\n",
            "Avg RMSE: 0.79\n",
            "Avg RÂ²: 0.6235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MSE -> HuberLossë¡œ ë°”ê¾¸ê³  ë‹¤ì‹œ ì‹¤í–‰\n",
        "\n",
        "# 1. ì‹œë“œ ê³ ì •\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# 2. ì •ë ¬ ë³´ì¥ëœ groupby â†’ í…ì„œ êµ¬ì„±\n",
        "df = df.sort_values(\"nickname\")  # í•„ìˆ˜ ì •ë ¬\n",
        "\n",
        "# ì¥ë¹„ ìˆ˜ íŒŒìƒ í”¼ì²˜\n",
        "equip_counts = mask.sum(dim=1).unsqueeze(1).repeat(1, x_cont.shape[1]).unsqueeze(2)\n",
        "x_cont_with_count = torch.cat([x_cont, equip_counts], dim=2)\n",
        "\n",
        "# 3. ë”¥ëŸ¬ë‹ ëª¨ë¸ ì •ì˜\n",
        "class DeepMaskedModel(nn.Module):\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)  # Softplus ì œê±°: ì „íˆ¬ë ¥ ì§ì ‘ ì˜ˆì¸¡\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        emb_cat = torch.cat(embs, dim=-1)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        encoded = self.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "        return self.rho(pooled).squeeze()\n",
        "\n",
        "# 4. K-Fold í•™ìŠµ ë° í‰ê°€\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmses, r2s = [], []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(x_cat)):\n",
        "    print(f\"\\nğŸ“‚ Fold {fold + 1}\")\n",
        "\n",
        "    train_set = TensorDataset(x_cat[train_idx], x_cont_with_count[train_idx], mask[train_idx], y[train_idx])\n",
        "    val_set = TensorDataset(x_cat[val_idx], x_cont_with_count[val_idx], mask[val_idx], y[val_idx])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=256, shuffle=False)\n",
        "\n",
        "    model = DeepMaskedModel(embedding_info, x_cont_with_count.shape[-1])\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.HuberLoss(delta=1.0)\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb, xfb, mb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader.dataset):.4f}\")\n",
        "\n",
        "    # Foldë³„ í‰ê°€\n",
        "    model.eval()\n",
        "    preds_all, y_all = [], []\n",
        "    with torch.no_grad():\n",
        "        for xcb, xfb, mb, yb in val_loader:\n",
        "            preds = model(xcb, xfb, mb)\n",
        "            preds_all.append(preds.numpy())\n",
        "            y_all.append(yb.numpy())\n",
        "\n",
        "    pred_all = np.concatenate(preds_all)\n",
        "    y_true = np.concatenate(y_all)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred_all))\n",
        "    r2 = r2_score(y_true, pred_all)\n",
        "    rmses.append(rmse)\n",
        "    r2s.append(r2)\n",
        "\n",
        "    print(f\"âœ… Fold {fold+1} RMSE: {rmse:,.2f}, RÂ²: {r2:.4f}\")\n",
        "\n",
        "# ìµœì¢… í‰ê·  ì¶œë ¥\n",
        "print(\"\\nğŸ¯ K-Fold í‰ê·  ì„±ëŠ¥:\")\n",
        "print(f\"Avg RMSE: {np.mean(rmses):,.2f}\")\n",
        "print(f\"Avg RÂ²: {np.mean(r2s):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3lXbQXB7jhC",
        "outputId": "7770b830-c455-46b1-bcea-7946cd96b97f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“‚ Fold 1\n",
            "Epoch 1: Loss = 0.4246\n",
            "Epoch 2: Loss = 0.1550\n",
            "Epoch 3: Loss = 0.1408\n",
            "Epoch 4: Loss = 0.1360\n",
            "Epoch 5: Loss = 0.1363\n",
            "Epoch 6: Loss = 0.1286\n",
            "Epoch 7: Loss = 0.1292\n",
            "Epoch 8: Loss = 0.1271\n",
            "Epoch 9: Loss = 0.1229\n",
            "Epoch 10: Loss = 0.1238\n",
            "âœ… Fold 1 RMSE: 0.77, RÂ²: 0.6381\n",
            "\n",
            "ğŸ“‚ Fold 2\n",
            "Epoch 1: Loss = 0.4636\n",
            "Epoch 2: Loss = 0.1583\n",
            "Epoch 3: Loss = 0.1492\n",
            "Epoch 4: Loss = 0.1358\n",
            "Epoch 5: Loss = 0.1315\n",
            "Epoch 6: Loss = 0.1290\n",
            "Epoch 7: Loss = 0.1218\n",
            "Epoch 8: Loss = 0.1197\n",
            "Epoch 9: Loss = 0.1187\n",
            "Epoch 10: Loss = 0.1171\n",
            "âœ… Fold 2 RMSE: 0.76, RÂ²: 0.6004\n",
            "\n",
            "ğŸ“‚ Fold 3\n",
            "Epoch 1: Loss = 0.4842\n",
            "Epoch 2: Loss = 0.1509\n",
            "Epoch 3: Loss = 0.1406\n",
            "Epoch 4: Loss = 0.1307\n",
            "Epoch 5: Loss = 0.1260\n",
            "Epoch 6: Loss = 0.1266\n",
            "Epoch 7: Loss = 0.1258\n",
            "Epoch 8: Loss = 0.1241\n",
            "Epoch 9: Loss = 0.1102\n",
            "Epoch 10: Loss = 0.1194\n",
            "âœ… Fold 3 RMSE: 0.97, RÂ²: 0.4501\n",
            "\n",
            "ğŸ“‚ Fold 4\n",
            "Epoch 1: Loss = 0.4939\n",
            "Epoch 2: Loss = 0.1481\n",
            "Epoch 3: Loss = 0.1389\n",
            "Epoch 4: Loss = 0.1369\n",
            "Epoch 5: Loss = 0.1300\n",
            "Epoch 6: Loss = 0.1256\n",
            "Epoch 7: Loss = 0.1261\n",
            "Epoch 8: Loss = 0.1222\n",
            "Epoch 9: Loss = 0.1181\n",
            "Epoch 10: Loss = 0.1185\n",
            "âœ… Fold 4 RMSE: 0.86, RÂ²: 0.5968\n",
            "\n",
            "ğŸ“‚ Fold 5\n",
            "Epoch 1: Loss = 0.4897\n",
            "Epoch 2: Loss = 0.1566\n",
            "Epoch 3: Loss = 0.1433\n",
            "Epoch 4: Loss = 0.1303\n",
            "Epoch 5: Loss = 0.1328\n",
            "Epoch 6: Loss = 0.1216\n",
            "Epoch 7: Loss = 0.1226\n",
            "Epoch 8: Loss = 0.1149\n",
            "Epoch 9: Loss = 0.1214\n",
            "Epoch 10: Loss = 0.1138\n",
            "âœ… Fold 5 RMSE: 0.78, RÂ²: 0.6547\n",
            "\n",
            "ğŸ¯ K-Fold í‰ê·  ì„±ëŠ¥:\n",
            "Avg RMSE: 0.83\n",
            "Avg RÂ²: 0.5880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: ì˜¤ì°¨ í° ìºë¦­í„°ë§Œ ì¶”ì¶œí•˜ì—¬ fine-tuneìš© í…ì„œ êµ¬ì„±\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred_all = model(x_cat, x_cont_with_count, mask).numpy()\n",
        "    y_all = y.numpy()\n",
        "\n",
        "# ìƒìœ„ 10% ì˜¤ì°¨ ìœ ì €ë¥¼ ëŒ€ìƒ\n",
        "abs_errors = np.abs(pred_all - y_all)\n",
        "threshold = np.percentile(abs_errors, 90)  # ìƒìœ„ 10%\n",
        "error_indices = np.where(abs_errors > threshold)[0]\n",
        "print(f\"ğŸ¯ ìƒìœ„ 10% ì˜¤ì°¨ ìºë¦­í„° ìˆ˜: {len(error_indices)}\")\n",
        "\n",
        "# í•´ë‹¹ ì¸ë±ìŠ¤ì˜ í…ì„œë§Œ ì¶”ì¶œ\n",
        "x_cat_ft = x_cat[error_indices]\n",
        "x_cont_ft = x_cont_with_count[error_indices]\n",
        "mask_ft = mask[error_indices]\n",
        "y_ft = y[error_indices]\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "ft_dataset = TensorDataset(x_cat_ft, x_cont_ft, mask_ft, y_ft)\n",
        "ft_loader = DataLoader(ft_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Step 2: ê¸°ì¡´ ëª¨ë¸ ê·¸ëŒ€ë¡œ ë¶ˆëŸ¬ì™€ fine-tune (3 epoch)\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for epoch in range(3):\n",
        "    total_loss = 0\n",
        "    for xcb, xfb, mb, yb in ft_loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xcb, xfb, mb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * len(xcb)\n",
        "    print(f\"ğŸ”§ Fine-tune Epoch {epoch+1}: Loss = {total_loss / len(ft_loader.dataset):.4f}\")\n",
        "\n",
        "# Step 3: ì „ì²´ RMSE ë‹¤ì‹œ í‰ê°€\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    final_pred = model(x_cat, x_cont_with_count, mask).numpy()\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "final_rmse = np.sqrt(mean_squared_error(y_all, final_pred))\n",
        "final_r2 = r2_score(y_all, final_pred)\n",
        "\n",
        "print(f\"\\nğŸ“Š Fine-tune ì´í›„ ì „ì²´ í‰ê°€:\")\n",
        "print(f\"RMSE: {final_rmse:,.2f}\")\n",
        "print(f\"RÂ²: {final_r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSUuqZZK7jeg",
        "outputId": "f9891c33-c58f-4b00-fa05-28b68c1652dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¯ ìƒìœ„ 10% ì˜¤ì°¨ ìºë¦­í„° ìˆ˜: 4577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”§ Fine-tune Epoch 1: Loss = 4.3509\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 4.0787\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 3.8983\n",
            "\n",
            "ğŸ“Š Fine-tune ì´í›„ ì „ì²´ í‰ê°€:\n",
            "RMSE: 0.76\n",
            "RÂ²: 0.6604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: ì˜¤ì°¨ í° ìºë¦­í„°ë§Œ ì¶”ì¶œí•˜ì—¬ fine-tuneìš© í…ì„œ êµ¬ì„±\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred_all = model(x_cat, x_cont_with_count, mask).numpy()\n",
        "    y_all = y.numpy()\n",
        "\n",
        "# ìƒìœ„ 30% ì˜¤ì°¨ ìœ ì €ë¥¼ ëŒ€ìƒ\n",
        "abs_errors = np.abs(pred_all - y_all)\n",
        "threshold = np.percentile(abs_errors, 70)  # ìƒìœ„ 30% ì»¤íŠ¸ë¼ì¸\n",
        "error_indices = np.where(abs_errors > threshold)[0]\n",
        "print(f\"ğŸ¯ ìƒìœ„ 30% ì˜¤ì°¨ ìºë¦­í„° ìˆ˜: {len(error_indices)}\")\n",
        "\n",
        "# í•´ë‹¹ ì¸ë±ìŠ¤ì˜ í…ì„œë§Œ ì¶”ì¶œ\n",
        "x_cat_ft = x_cat[error_indices]\n",
        "x_cont_ft = x_cont_with_count[error_indices]\n",
        "mask_ft = mask[error_indices]\n",
        "y_ft = y[error_indices]\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "ft_dataset = TensorDataset(x_cat_ft, x_cont_ft, mask_ft, y_ft)\n",
        "ft_loader = DataLoader(ft_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Step 2: ê¸°ì¡´ ëª¨ë¸ ê·¸ëŒ€ë¡œ ë¶ˆëŸ¬ì™€ fine-tune (3 epoch)\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for epoch in range(3):\n",
        "    total_loss = 0\n",
        "    for xcb, xfb, mb, yb in ft_loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xcb, xfb, mb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * len(xcb)\n",
        "    print(f\"ğŸ”§ Fine-tune Epoch {epoch+1}: Loss = {total_loss / len(ft_loader.dataset):.4f}\")\n",
        "\n",
        "# Step 3: ì „ì²´ RMSE ë‹¤ì‹œ í‰ê°€\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    final_pred = model(x_cat, x_cont_with_count, mask).numpy()\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "final_rmse = np.sqrt(mean_squared_error(y_all, final_pred))\n",
        "final_r2 = r2_score(y_all, final_pred)\n",
        "\n",
        "print(f\"\\nğŸ“Š Fine-tune ì´í›„ ì „ì²´ í‰ê°€:\")\n",
        "print(f\"RMSE: {final_rmse:,.2f}\")\n",
        "print(f\"RÂ²: {final_r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfxXyTI_-vDP",
        "outputId": "035498be-b1d1-4d44-cfdb-b09f606e62e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¯ ìƒìœ„ 30% ì˜¤ì°¨ ìºë¦­í„° ìˆ˜: 13731\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.4933\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.4428\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.4206\n",
            "\n",
            "ğŸ“Š Fine-tune ì´í›„ ì „ì²´ í‰ê°€:\n",
            "RMSE: 0.71\n",
            "RÂ²: 0.7001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# ëª¨ë¸ ì €ì¥ ê²½ë¡œ ì„¤ì •\n",
        "save_path = \"best_model_r2_0700_rmse_071.pt\"\n",
        "\n",
        "# ëª¨ë¸ state_dict ì €ì¥\n",
        "torch.save(model.state_dict(), save_path)\n",
        "\n",
        "print(f\"âœ… ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {save_path}\")\n",
        "\n",
        "# ì„±ëŠ¥ ìš”ì•½í‘œ ì •ë¦¬\n",
        "results = pd.DataFrame([\n",
        "    {\"ëª¨ë¸\": \"ê¸°ë³¸ DeepSets\", \"RMSE\": 0.79, \"RÂ²\": 0.6235},\n",
        "    {\"ëª¨ë¸\": \"DeepSets + HuberLoss\", \"RMSE\": 0.83, \"RÂ²\": 0.5880},\n",
        "    {\"ëª¨ë¸\": \"DeepSets + Fine-Tune (10%)\", \"RMSE\": 0.76, \"RÂ²\": 0.6604},\n",
        "    {\"ëª¨ë¸\": \"DeepSets + Fine-Tune (30%)\", \"RMSE\": 0.71, \"RÂ²\": 0.7001},\n",
        "    {\"ëª¨ë¸\": \"Attention êµ¬ì¡°\", \"RMSE\": 0.76, \"RÂ²\": 0.6547},\n",
        "    {\"ëª¨ë¸\": \"Attention êµ¬ì¡° + ì˜ëª»ëœ fine-tune\", \"RMSE\": 1.12, \"RÂ²\": 0.2606},\n",
        "])\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "iBahcfJr7jas",
        "outputId": "ae3fe719-f95c-4df1-f034-d0b753b5f9f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: best_model_r2_0700_rmse_071.pt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             ëª¨ë¸  RMSE      RÂ²\n",
              "0                   ê¸°ë³¸ DeepSets  0.79  0.6235\n",
              "1          DeepSets + HuberLoss  0.83  0.5880\n",
              "2    DeepSets + Fine-Tune (10%)  0.76  0.6604\n",
              "3    DeepSets + Fine-Tune (30%)  0.71  0.7001\n",
              "4                  Attention êµ¬ì¡°  0.76  0.6547\n",
              "5  Attention êµ¬ì¡° + ì˜ëª»ëœ fine-tune  1.12  0.2606"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d38a0490-8b86-4ab3-b9c2-0cb23729ce86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ëª¨ë¸</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>RÂ²</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ê¸°ë³¸ DeepSets</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.6235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DeepSets + HuberLoss</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.5880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DeepSets + Fine-Tune (10%)</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.6604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DeepSets + Fine-Tune (30%)</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.7001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Attention êµ¬ì¡°</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.6547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Attention êµ¬ì¡° + ì˜ëª»ëœ fine-tune</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0.2606</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d38a0490-8b86-4ab3-b9c2-0cb23729ce86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d38a0490-8b86-4ab3-b9c2-0cb23729ce86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d38a0490-8b86-4ab3-b9c2-0cb23729ce86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-336ccb65-2200-43dd-a0be-69f679ea8d8a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-336ccb65-2200-43dd-a0be-69f679ea8d8a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-336ccb65-2200-43dd-a0be-69f679ea8d8a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0e37f8c4-2a6d-418e-aade-e310b6ddcb80\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0e37f8c4-2a6d-418e-aade-e310b6ddcb80 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"\\ubaa8\\ub378\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"\\uae30\\ubcf8 DeepSets\",\n          \"DeepSets + HuberLoss\",\n          \"Attention \\uad6c\\uc870 + \\uc798\\ubabb\\ub41c fine-tune\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RMSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1482452922242952,\n        \"min\": 0.71,\n        \"max\": 1.12,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.83,\n          1.12,\n          0.76\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R\\u00b2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16151284056280685,\n        \"min\": 0.2606,\n        \"max\": 0.7001,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.6235,\n          0.588,\n          0.2606\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"best_model_r2_0700_rmse_071.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "kujWA7NTJrRJ",
        "outputId": "f01a3c77-3584-453e-afab-1ff6b89ed8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ab8df380-73fe-4e14-9541-2a3f40f583e0\", \"best_model_r2_0700_rmse_071.pt\", 439294)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ë¶ˆëŸ¬ì˜¬ ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜\n",
        "class DeepMaskedModel(nn.Module):\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        emb_cat = torch.cat(embs, dim=-1)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        encoded = self.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "        return self.rho(pooled).squeeze()\n",
        "\n",
        "# ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í›„ .pt íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "model = DeepMaskedModel(embedding_info, x_cont_with_count.shape[-1])\n",
        "\n",
        "# ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
        "model.load_state_dict(torch.load(\"best_model_r2_0700_rmse_071.pt\"))\n",
        "\n",
        "# ì˜ˆì¸¡ìš© ëª¨ë“œë¡œ ì „í™˜\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "id": "DQ1PCHEVJrOj",
        "outputId": "bc06d9e2-85e5-4c7c-c2d8-19e06b503e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for DeepMaskedModel:\n\tUnexpected key(s) in state_dict: \"attention_score.weight\", \"attention_score.bias\", \"rho.4.weight\", \"rho.4.bias\". \n\tsize mismatch for embeddings.subclass.weight: copying a param with shape torch.Size([46, 16]) from checkpoint, the shape in current model is torch.Size([46, 8]).\n\tsize mismatch for embeddings.equipment_slot.weight: copying a param with shape torch.Size([24, 16]) from checkpoint, the shape in current model is torch.Size([24, 8]).\n\tsize mismatch for embeddings.main_stat_type.weight: copying a param with shape torch.Size([6, 16]) from checkpoint, the shape in current model is torch.Size([6, 8]).\n\tsize mismatch for embeddings.item_group.weight: copying a param with shape torch.Size([15, 16]) from checkpoint, the shape in current model is torch.Size([15, 8]).\n\tsize mismatch for embeddings.starforce_scroll_flag.weight: copying a param with shape torch.Size([2, 16]) from checkpoint, the shape in current model is torch.Size([2, 8]).\n\tsize mismatch for embeddings.potential_option_grade.weight: copying a param with shape torch.Size([6, 16]) from checkpoint, the shape in current model is torch.Size([6, 8]).\n\tsize mismatch for embeddings.additional_potential_option_grade.weight: copying a param with shape torch.Size([6, 16]) from checkpoint, the shape in current model is torch.Size([6, 8]).\n\tsize mismatch for embeddings.main_pot_grade_summary.weight: copying a param with shape torch.Size([42, 16]) from checkpoint, the shape in current model is torch.Size([42, 8]).\n\tsize mismatch for embeddings.add_pot_grade_summary.weight: copying a param with shape torch.Size([55, 16]) from checkpoint, the shape in current model is torch.Size([55, 8]).\n\tsize mismatch for embeddings.potential_status.weight: copying a param with shape torch.Size([27, 16]) from checkpoint, the shape in current model is torch.Size([27, 8]).\n\tsize mismatch for phi.0.weight: copying a param with shape torch.Size([256, 179]) from checkpoint, the shape in current model is torch.Size([256, 99]).\n\tsize mismatch for rho.0.weight: copying a param with shape torch.Size([128, 64]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for rho.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for rho.2.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([1, 32]).\n\tsize mismatch for rho.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([1]).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-155116b9c2f5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_model_r2_0700_rmse_071.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# ì˜ˆì¸¡ìš© ëª¨ë“œë¡œ ì „í™˜\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2581\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2582\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2583\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DeepMaskedModel:\n\tUnexpected key(s) in state_dict: \"attention_score.weight\", \"attention_score.bias\", \"rho.4.weight\", \"rho.4.bias\". \n\tsize mismatch for embeddings.subclass.weight: copying a param with shape torch.Size([46, 16]) from checkpoint, the shape in current model is torch.Size([46, 8]).\n\tsize mismatch for embeddings.equipment_slot.weight: copying a param with shape torch.Size([24, 16]) from checkpoint, the shape in current model is torch.Size([24, 8]).\n\tsize mismatch for embeddings.main_stat_type.weight: copying a param with shape torch.Size([6, 16]) from checkpoint, the shape in current model is torch.Size([6, 8]).\n\tsize mismatch for embeddings.item_group.weight: copying a param with shape torch.Size([15, 16]) from checkpoint, the shape in current model is torch.Size([15, 8]).\n\tsize mismatch for embeddings.starforce_scroll_flag.weight: copying a param with shape torch.Size([2, 16]) from checkpoint, the shape in current model is torch.Size([2, 8]).\n\tsize mismatch for embeddings.potential_option_grade.weight: copying a param with shape torch.Size([6, 16]) from checkpoint, the shape in current model is torch.Size([6, 8]).\n\tsize mismatch for embeddings.additional_potential_option_grade.weight: copying a param with shape torch.Size([6, 16]) from checkpoint, the shape in current model is torch.Size([6, 8]).\n\tsize mismatch for embeddings.main_pot_grade_summary.weight: copying a param with shape torch.Size([42, 16]) from checkpoint, the shape in current model is torch.Size([42, 8]).\n\tsize mismatch for embeddings.add_pot_grade_summary.weight: copying a param with shape torch.Size([55, 16]) from checkpoint, the shape in current model is torch.Size([55, 8]).\n\tsize mismatch for embeddings.potential_status.weight: copying a param with shape torch.Size([27, 16]) from checkpoint, the shape in current model is torch.Size([27, 8]).\n\tsize mismatch for phi.0.weight: copying a param with shape torch.Size([256, 179]) from checkpoint, the shape in current model is torch.Size([256, 99]).\n\tsize mismatch for rho.0.weight: copying a param with shape torch.Size([128, 64]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for rho.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for rho.2.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([1, 32]).\n\tsize mismatch for rho.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([1])."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ë¶ˆëŸ¬ì˜¬ ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜\n",
        "class AttentionMaskedModelV2(nn.Module):\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=16, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.attention_score = nn.Linear(64, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        emb_cat = torch.cat(embs, dim=-1)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        h = self.phi(x)\n",
        "        attn_scores = self.attention_score(h).squeeze(-1)\n",
        "        attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))\n",
        "        attn_weights = F.softmax(attn_scores, dim=1).unsqueeze(-1)\n",
        "        weighted_sum = torch.sum(h * self.dropout(attn_weights), dim=1)\n",
        "        return self.rho(weighted_sum).squeeze()"
      ],
      "metadata": {
        "id": "HywiqU1IJrKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ ìƒì„± ì‹œ embedding_info, ì—°ì†í˜• í”¼ì²˜ ì°¨ì› ìˆ˜ ì¼ì¹˜ì‹œí‚¤ê¸°\n",
        "model = AttentionMaskedModelV2(embedding_info, x_cont_with_count.shape[-1])\n",
        "\n",
        "# ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "model.load_state_dict(torch.load(\"best_model_r2_0700_rmse_071.pt\"))\n",
        "\n",
        "# í‰ê°€ ëª¨ë“œ ì „í™˜\n",
        "model.eval()\n",
        "print(\"ëª¨ë¸ ë¡œë”© ì„±ê³µ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb3ELcFv7jTM",
        "outputId": "8599855c-6c08-4b29-b95a-42f524b1c49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ëª¨ë¸ ë¡œë”© ì„±ê³µ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ê°€ì¥ ì„±ëŠ¥ ì¢‹ì•˜ë˜ ëª¨ë¸ ì €ì¥í•˜ê¸°"
      ],
      "metadata": {
        "id": "iFa_w8VGq5Pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "rN888wbzwjkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ì‹œë“œ ì„¤ì •\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# 2. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ë³‘í•©\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/item_nomissingvalues_copy.csv', na_values=[], keep_default_na=False)\n",
        "df_stat = pd.read_csv('/content/drive/MyDrive/data/merged/stat_merged.csv')\n",
        "df_stat_trimmed = df_stat[['nickname', 'subclass', 'ì „íˆ¬ë ¥']].drop_duplicates()\n",
        "df = df.merge(df_stat_trimmed, on=['nickname', 'subclass'], how='left')\n",
        "df.dropna(subset=['ì „íˆ¬ë ¥'], inplace=True)\n",
        "\n",
        "# 3. ì „ì²˜ë¦¬\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "df = df.dropna(subset=cat_cols + num_cols + ['ì „íˆ¬ë ¥'])\n",
        "encoders = {col: LabelEncoder().fit(df[col]) for col in cat_cols}\n",
        "for col in cat_cols:\n",
        "    df[col] = encoders[col].transform(df[col])\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "df['log_ì „íˆ¬ë ¥'] = np.log1p(df['ì „íˆ¬ë ¥'])  # ë¡œê·¸ ë³€í™˜\n",
        "\n",
        "# 4. ì‹œí€€ìŠ¤ êµ¬ì„±\n",
        "df = df.sort_values(\"nickname\")\n",
        "max_len = 24\n",
        "x_cat_list, x_cont_list, mask_list, y_list = [], [], [], []\n",
        "\n",
        "for name, group in df.groupby(\"nickname\"):\n",
        "    cat = group[cat_cols].values.astype(np.int64)\n",
        "    cont = group[num_cols].values.astype(np.float32)\n",
        "    valid_len = len(group)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        pad_cat = np.zeros((max_len - valid_len, len(cat_cols)))\n",
        "        pad_cont = np.zeros((max_len - valid_len, len(num_cols)))\n",
        "        pad_mask = [0] * (max_len - valid_len)\n",
        "        cat = np.vstack([cat, pad_cat])\n",
        "        cont = np.vstack([cont, pad_cont])\n",
        "        mask = [1] * valid_len + pad_mask\n",
        "    else:\n",
        "        cat = cat[:max_len]\n",
        "        cont = cont[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    x_cat_list.append(torch.tensor(cat, dtype=torch.long))\n",
        "    x_cont_list.append(torch.tensor(cont, dtype=torch.float32))\n",
        "    mask_list.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    y_list.append(np.log1p(group['ì „íˆ¬ë ¥'].iloc[0]))\n",
        "\n",
        "x_cat = torch.stack(x_cat_list)\n",
        "x_cont = torch.stack(x_cont_list)\n",
        "mask = torch.stack(mask_list) # ì´ 24ê°œì˜ ìŠ¬ë¡¯ ì¤‘ ëª‡ ê°œ ì•ˆ ë‚€ ì• ê°€ ìˆë‹¤ë©´ ì—†ëŠ” ì¥ë¹„ì— ëŒ€í•´ì„œëŠ” ë¬´ì‹œ\n",
        "y = torch.tensor(y_list, dtype=torch.float32)\n",
        "\n",
        "equip_counts = mask.sum(dim=1).unsqueeze(1).repeat(1, x_cont.shape[1]).unsqueeze(2)\n",
        "x_cont_with_count = torch.cat([x_cont, equip_counts], dim=2)\n",
        "embedding_info = {col: df[col].nunique() for col in cat_cols}\n",
        "\n",
        "# 5. ëª¨ë¸ ì •ì˜\n",
        "class DeepMaskedModel(nn.Module): # Deepsets\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        emb_cat = torch.cat(embs, dim=-1)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        encoded = self.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "        return self.rho(pooled).squeeze()\n",
        "\n",
        "# 6. K-Fold + Fine-tune\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmses, r2s = [], []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(x_cat)):\n",
        "    print(f\"\\nğŸ“‚ Fold {fold + 1}\")\n",
        "\n",
        "    train_set = TensorDataset(x_cat[train_idx], x_cont_with_count[train_idx], mask[train_idx], y[train_idx])\n",
        "    val_set = TensorDataset(x_cat[val_idx], x_cont_with_count[val_idx], mask[val_idx], y[val_idx])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=256, shuffle=False)\n",
        "\n",
        "    model = DeepMaskedModel(embedding_info, x_cont_with_count.shape[-1])\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb, xfb, mb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader.dataset):.4f}\")\n",
        "\n",
        "    # ìƒìœ„ 30% ì˜¤ì°¨ ìºë¦­í„°ë§Œ Fine-tune\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred_all = model(x_cat, x_cont_with_count, mask).numpy()\n",
        "        y_all = y.numpy()\n",
        "    abs_errors = np.abs(pred_all - y_all)\n",
        "    threshold = np.percentile(abs_errors, 70)\n",
        "    error_indices = np.where(abs_errors > threshold)[0]\n",
        "\n",
        "    ft_set = TensorDataset(\n",
        "        x_cat[error_indices],\n",
        "        x_cont_with_count[error_indices],\n",
        "        mask[error_indices],\n",
        "        y[error_indices]\n",
        "    )\n",
        "    ft_loader = DataLoader(ft_set, batch_size=32, shuffle=True)\n",
        "\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    for epoch in range(3):\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in ft_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb, xfb, mb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"ğŸ”§ Fine-tune Epoch {epoch+1}: Loss = {total_loss / len(ft_loader.dataset):.4f}\")\n",
        "\n",
        "    # í‰ê°€\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        final_pred = model(x_cat, x_cont_with_count, mask).numpy()\n",
        "\n",
        "    final_rmse = np.sqrt(mean_squared_error(y_all, final_pred))\n",
        "    final_r2 = r2_score(y_all, final_pred)\n",
        "\n",
        "    print(f\"âœ… Fold {fold+1} Final RMSE: {final_rmse:,.2f}, RÂ²: {final_r2:.4f}\")\n",
        "    rmses.append(final_rmse)\n",
        "    r2s.append(final_r2)\n",
        "\n",
        "# ìµœì¢… ì„±ëŠ¥ ì¶œë ¥\n",
        "print(f\"\\nğŸ¯ í‰ê·  ì„±ëŠ¥: RMSE = {np.mean(rmses):,.2f}, RÂ² = {np.mean(r2s):.4f}\")\n",
        "\n",
        "# ëª¨ë¸ ì €ì¥\n",
        "torch.save(model.state_dict(), f\"best_model_r2_{np.mean(r2s):.4f}_rmse_{np.mean(rmses):.2f}.pt\")\n",
        "print(\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43hv7AIZ0BY6",
        "outputId": "942453ae-d0b6-46e0-c665-8d107550f5c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“‚ Fold 1\n",
            "Epoch 1: Loss = 3.4882\n",
            "Epoch 2: Loss = 0.7373\n",
            "Epoch 3: Loss = 0.6872\n",
            "Epoch 4: Loss = 0.6495\n",
            "Epoch 5: Loss = 0.6062\n",
            "Epoch 6: Loss = 0.5705\n",
            "Epoch 7: Loss = 0.5539\n",
            "Epoch 8: Loss = 0.5349\n",
            "Epoch 9: Loss = 0.5038\n",
            "Epoch 10: Loss = 0.5001\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.2077\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.1489\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.1188\n",
            "âœ… Fold 1 Final RMSE: 0.67, RÂ²: 0.7328\n",
            "\n",
            "ğŸ“‚ Fold 2\n",
            "Epoch 1: Loss = 3.4654\n",
            "Epoch 2: Loss = 0.7116\n",
            "Epoch 3: Loss = 0.6481\n",
            "Epoch 4: Loss = 0.6123\n",
            "Epoch 5: Loss = 0.5787\n",
            "Epoch 6: Loss = 0.5548\n",
            "Epoch 7: Loss = 0.5422\n",
            "Epoch 8: Loss = 0.5196\n",
            "Epoch 9: Loss = 0.4873\n",
            "Epoch 10: Loss = 0.4991\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.1377\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.0677\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.0406\n",
            "âœ… Fold 2 Final RMSE: 0.72, RÂ²: 0.6951\n",
            "\n",
            "ğŸ“‚ Fold 3\n",
            "Epoch 1: Loss = 4.4264\n",
            "Epoch 2: Loss = 0.6740\n",
            "Epoch 3: Loss = 0.6047\n",
            "Epoch 4: Loss = 0.5652\n",
            "Epoch 5: Loss = 0.5611\n",
            "Epoch 6: Loss = 0.5318\n",
            "Epoch 7: Loss = 0.5050\n",
            "Epoch 8: Loss = 0.5109\n",
            "Epoch 9: Loss = 0.4738\n",
            "Epoch 10: Loss = 0.4611\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.0123\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 0.9737\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 0.9490\n",
            "âœ… Fold 3 Final RMSE: 0.69, RÂ²: 0.7164\n",
            "\n",
            "ğŸ“‚ Fold 4\n",
            "Epoch 1: Loss = 4.2300\n",
            "Epoch 2: Loss = 0.6981\n",
            "Epoch 3: Loss = 0.6211\n",
            "Epoch 4: Loss = 0.5966\n",
            "Epoch 5: Loss = 0.5804\n",
            "Epoch 6: Loss = 0.5514\n",
            "Epoch 7: Loss = 0.5355\n",
            "Epoch 8: Loss = 0.5072\n",
            "Epoch 9: Loss = 0.5129\n",
            "Epoch 10: Loss = 0.4872\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.2825\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.2302\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.1989\n",
            "âœ… Fold 4 Final RMSE: 0.76, RÂ²: 0.6542\n",
            "\n",
            "ğŸ“‚ Fold 5\n",
            "Epoch 1: Loss = 3.5911\n",
            "Epoch 2: Loss = 0.7226\n",
            "Epoch 3: Loss = 0.6645\n",
            "Epoch 4: Loss = 0.6251\n",
            "Epoch 5: Loss = 0.5922\n",
            "Epoch 6: Loss = 0.5834\n",
            "Epoch 7: Loss = 0.5447\n",
            "Epoch 8: Loss = 0.5446\n",
            "Epoch 9: Loss = 0.4935\n",
            "Epoch 10: Loss = 0.4953\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.2455\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.1639\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.1187\n",
            "âœ… Fold 5 Final RMSE: 0.66, RÂ²: 0.7432\n",
            "\n",
            "ğŸ¯ í‰ê·  ì„±ëŠ¥: RMSE = 0.70, RÂ² = 0.7083\n",
            "âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ëª¨ë¸ ì‚¬ìš©í•˜ê¸°"
      ],
      "metadata": {
        "id": "3lRcPxNfrhwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- í˜„ì¬ ìƒí™©: ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì „íˆ¬ë ¥ ì˜ˆì¸¡ê¸°ëŠ” ê½¤ë‚˜ ì˜ ë§Œë“¤ì–´ì§\n",
        "- í˜„ì¬ ë¬¸ì œì : ê·¼ë° ì´ê±¸ ì‚¬ìš©í•˜ë ¤ë©´ ë‰´ë¹„ ìœ ì € ì…ì¥ì—ì„œ ì•„ì´í…œ 24ê°œì˜ ì •ë³´ë¥¼ ì„¸ì„¸í•˜ê²Œ ë‹¤ ì…ë ¥í•´ì•¼(ì…ë ¥ê°’ íˆ¬ë¨¸ì¹˜) ì •í™•í•˜ê²Œ ì „íˆ¬ë ¥ë¥¼ ì˜ˆì¸¡ë°›ì„ ìˆ˜ ìˆìŒ"
      ],
      "metadata": {
        "id": "FRfoE3dklgrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì‚¬ìš©í•  ëª¨ë¸ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "# 1. ì‹œë“œ ì„¤ì •\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# 2. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ë³‘í•©\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/item_nomissingvalues_copy.csv', na_values=[], keep_default_na=False)\n",
        "df_stat = pd.read_csv('/content/drive/MyDrive/data/merged/stat_merged.csv')\n",
        "df_stat_trimmed = df_stat[['nickname', 'subclass', 'ì „íˆ¬ë ¥']].drop_duplicates()\n",
        "df = df.merge(df_stat_trimmed, on=['nickname', 'subclass'], how='left')\n",
        "df.dropna(subset=['ì „íˆ¬ë ¥'], inplace=True)\n",
        "\n",
        "# 3. ì „ì²˜ë¦¬\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "df = df.dropna(subset=cat_cols + num_cols + ['ì „íˆ¬ë ¥'])\n",
        "encoders = {col: LabelEncoder().fit(df[col]) for col in cat_cols}\n",
        "for col in cat_cols:\n",
        "    df[col] = encoders[col].transform(df[col])\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "df['log_ì „íˆ¬ë ¥'] = np.log1p(df['ì „íˆ¬ë ¥'])  # ë¡œê·¸ ë³€í™˜\n",
        "\n",
        "# 4. ì‹œí€€ìŠ¤ êµ¬ì„±\n",
        "df = df.sort_values(\"nickname\")\n",
        "max_len = 24\n",
        "x_cat_list, x_cont_list, mask_list, y_list = [], [], [], []\n",
        "\n",
        "for name, group in df.groupby(\"nickname\"):\n",
        "    cat = group[cat_cols].values.astype(np.int64)\n",
        "    cont = group[num_cols].values.astype(np.float32)\n",
        "    valid_len = len(group)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        pad_cat = np.zeros((max_len - valid_len, len(cat_cols)))\n",
        "        pad_cont = np.zeros((max_len - valid_len, len(num_cols)))\n",
        "        pad_mask = [0] * (max_len - valid_len)\n",
        "        cat = np.vstack([cat, pad_cat])\n",
        "        cont = np.vstack([cont, pad_cont])\n",
        "        mask = [1] * valid_len + pad_mask\n",
        "    else:\n",
        "        cat = cat[:max_len]\n",
        "        cont = cont[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    x_cat_list.append(torch.tensor(cat, dtype=torch.long))\n",
        "    x_cont_list.append(torch.tensor(cont, dtype=torch.float32))\n",
        "    mask_list.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    y_list.append(np.log1p(group['ì „íˆ¬ë ¥'].iloc[0]))\n",
        "\n",
        "x_cat = torch.stack(x_cat_list)\n",
        "x_cont = torch.stack(x_cont_list)\n",
        "mask = torch.stack(mask_list) # ì´ 24ê°œì˜ ìŠ¬ë¡¯ ì¤‘ ëª‡ ê°œ ì•ˆ ë‚€ ì• ê°€ ìˆë‹¤ë©´ ì—†ëŠ” ì¥ë¹„ì— ëŒ€í•´ì„œëŠ” ë¬´ì‹œ\n",
        "y = torch.tensor(y_list, dtype=torch.float32)\n",
        "\n",
        "equip_counts = mask.sum(dim=1).unsqueeze(1).repeat(1, x_cont.shape[1]).unsqueeze(2)\n",
        "x_cont_with_count = torch.cat([x_cont, equip_counts], dim=2)\n",
        "embedding_info = {col: df[col].nunique() for col in cat_cols}\n",
        "\n",
        "# 5. ëª¨ë¸ ì •ì˜\n",
        "class DeepMaskedModel(nn.Module): # Deepsets\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        emb_cat = torch.cat(embs, dim=-1)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        encoded = self.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "        return self.rho(pooled).squeeze()\n",
        "\n",
        "# 6. K-Fold + Fine-tune\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmses, r2s = [], []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(x_cat)):\n",
        "    print(f\"\\nğŸ“‚ Fold {fold + 1}\")\n",
        "\n",
        "    train_set = TensorDataset(x_cat[train_idx], x_cont_with_count[train_idx], mask[train_idx], y[train_idx])\n",
        "    val_set = TensorDataset(x_cat[val_idx], x_cont_with_count[val_idx], mask[val_idx], y[val_idx])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=256, shuffle=False)\n",
        "\n",
        "    model = DeepMaskedModel(embedding_info, x_cont_with_count.shape[-1])\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb, xfb, mb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader.dataset):.4f}\")\n",
        "\n",
        "    # ìƒìœ„ 30% ì˜¤ì°¨ ìºë¦­í„°ë§Œ Fine-tune\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred_all = model(x_cat, x_cont_with_count, mask).numpy()\n",
        "        y_all = y.numpy()\n",
        "    abs_errors = np.abs(pred_all - y_all)\n",
        "    threshold = np.percentile(abs_errors, 70)\n",
        "    error_indices = np.where(abs_errors > threshold)[0]\n",
        "\n",
        "    ft_set = TensorDataset(\n",
        "        x_cat[error_indices],\n",
        "        x_cont_with_count[error_indices],\n",
        "        mask[error_indices],\n",
        "        y[error_indices]\n",
        "    )\n",
        "    ft_loader = DataLoader(ft_set, batch_size=32, shuffle=True)\n",
        "\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    for epoch in range(3):\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in ft_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb, xfb, mb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"ğŸ”§ Fine-tune Epoch {epoch+1}: Loss = {total_loss / len(ft_loader.dataset):.4f}\")\n",
        "\n",
        "    # í‰ê°€\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        final_pred = model(x_cat, x_cont_with_count, mask).numpy()\n",
        "\n",
        "    final_rmse = np.sqrt(mean_squared_error(y_all, final_pred))\n",
        "    final_r2 = r2_score(y_all, final_pred)\n",
        "\n",
        "    print(f\"âœ… Fold {fold+1} Final RMSE: {final_rmse:,.2f}, RÂ²: {final_r2:.4f}\")\n",
        "    rmses.append(final_rmse)\n",
        "    r2s.append(final_r2)\n",
        "\n",
        "# ìµœì¢… ì„±ëŠ¥ ì¶œë ¥\n",
        "print(f\"\\nğŸ¯ í‰ê·  ì„±ëŠ¥: RMSE = {np.mean(rmses):,.2f}, RÂ² = {np.mean(r2s):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YN5lKHpUiFQi",
        "outputId": "42da58b3-7c03-46f6-a649-35072df4db4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“‚ Fold 1\n",
            "Epoch 1: Loss = 3.4882\n",
            "Epoch 2: Loss = 0.7373\n",
            "Epoch 3: Loss = 0.6872\n",
            "Epoch 4: Loss = 0.6495\n",
            "Epoch 5: Loss = 0.6062\n",
            "Epoch 6: Loss = 0.5705\n",
            "Epoch 7: Loss = 0.5539\n",
            "Epoch 8: Loss = 0.5349\n",
            "Epoch 9: Loss = 0.5038\n",
            "Epoch 10: Loss = 0.5001\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.2077\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.1489\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.1188\n",
            "âœ… Fold 1 Final RMSE: 0.67, RÂ²: 0.7328\n",
            "\n",
            "ğŸ“‚ Fold 2\n",
            "Epoch 1: Loss = 3.4654\n",
            "Epoch 2: Loss = 0.7116\n",
            "Epoch 3: Loss = 0.6481\n",
            "Epoch 4: Loss = 0.6123\n",
            "Epoch 5: Loss = 0.5787\n",
            "Epoch 6: Loss = 0.5548\n",
            "Epoch 7: Loss = 0.5422\n",
            "Epoch 8: Loss = 0.5196\n",
            "Epoch 9: Loss = 0.4873\n",
            "Epoch 10: Loss = 0.4991\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.1377\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.0677\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.0406\n",
            "âœ… Fold 2 Final RMSE: 0.72, RÂ²: 0.6951\n",
            "\n",
            "ğŸ“‚ Fold 3\n",
            "Epoch 1: Loss = 4.4264\n",
            "Epoch 2: Loss = 0.6740\n",
            "Epoch 3: Loss = 0.6047\n",
            "Epoch 4: Loss = 0.5652\n",
            "Epoch 5: Loss = 0.5611\n",
            "Epoch 6: Loss = 0.5318\n",
            "Epoch 7: Loss = 0.5050\n",
            "Epoch 8: Loss = 0.5109\n",
            "Epoch 9: Loss = 0.4738\n",
            "Epoch 10: Loss = 0.4611\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.0123\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 0.9737\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 0.9490\n",
            "âœ… Fold 3 Final RMSE: 0.69, RÂ²: 0.7164\n",
            "\n",
            "ğŸ“‚ Fold 4\n",
            "Epoch 1: Loss = 4.2300\n",
            "Epoch 2: Loss = 0.6981\n",
            "Epoch 3: Loss = 0.6211\n",
            "Epoch 4: Loss = 0.5966\n",
            "Epoch 5: Loss = 0.5804\n",
            "Epoch 6: Loss = 0.5514\n",
            "Epoch 7: Loss = 0.5355\n",
            "Epoch 8: Loss = 0.5072\n",
            "Epoch 9: Loss = 0.5129\n",
            "Epoch 10: Loss = 0.4872\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.2825\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.2302\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.1989\n",
            "âœ… Fold 4 Final RMSE: 0.76, RÂ²: 0.6542\n",
            "\n",
            "ğŸ“‚ Fold 5\n",
            "Epoch 1: Loss = 3.5911\n",
            "Epoch 2: Loss = 0.7226\n",
            "Epoch 3: Loss = 0.6645\n",
            "Epoch 4: Loss = 0.6251\n",
            "Epoch 5: Loss = 0.5922\n",
            "Epoch 6: Loss = 0.5834\n",
            "Epoch 7: Loss = 0.5447\n",
            "Epoch 8: Loss = 0.5446\n",
            "Epoch 9: Loss = 0.4935\n",
            "Epoch 10: Loss = 0.4953\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.2455\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.1639\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.1187\n",
            "âœ… Fold 5 Final RMSE: 0.66, RÂ²: 0.7432\n",
            "\n",
            "ğŸ¯ í‰ê·  ì„±ëŠ¥: RMSE = 0.70, RÂ² = 0.7083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì¤‘ìš”ë„ê°€ ë†’ì€ ì¥ë¹„ ë¶€ìœ„ í™•ì¸"
      ],
      "metadata": {
        "id": "QA4zl01lmwEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_slot_importance(model, x_cat, x_cont, mask, y, cat_cols, equipment_slot_col, device='cpu'):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    # ì¥ë¹„ ìŠ¬ë¡¯ ì»¬ëŸ¼ ì¸ë±ìŠ¤\n",
        "    slot_idx = cat_cols.index(equipment_slot_col)\n",
        "\n",
        "    # ê¸°ë³¸ ì˜ˆì¸¡ê°’\n",
        "    with torch.no_grad():\n",
        "        base_pred = model(x_cat.to(device), x_cont.to(device), mask.to(device)).cpu().numpy()\n",
        "    y_true = y.numpy()\n",
        "    base_rmse = np.sqrt(((y_true - base_pred) ** 2).mean())\n",
        "\n",
        "    # ê³ ìœ  ìŠ¬ë¡¯ ì¶”ì¶œ\n",
        "    unique_slots = torch.unique(x_cat[:, :, slot_idx]).tolist()\n",
        "    slot_importance = {}\n",
        "\n",
        "    for slot in tqdm(unique_slots, desc=\"ğŸ“Š ì¥ë¹„ ì¤‘ìš”ë„ ë¶„ì„ ì¤‘\"):\n",
        "        # perturbí•  ìœ„ì¹˜ ë§ˆìŠ¤í¬\n",
        "        slot_mask = (x_cat[:, :, slot_idx] == slot)\n",
        "\n",
        "        # x_cat ë³µì œ\n",
        "        x_cat_perturbed = x_cat.clone()\n",
        "\n",
        "        # í•´ë‹¹ ìœ„ì¹˜ë§Œ ëœë¤ê°’ìœ¼ë¡œ ëŒ€ì²´ (í•´ë‹¹ ì¹¼ëŸ¼ë§Œ ë”°ë¡œ ì‘ì—…)\n",
        "        max_val = x_cat[:, :, slot_idx].max().item() + 1\n",
        "        rand_vals = torch.randint(0, max_val, slot_mask.shape)\n",
        "        x_cat_perturbed[:, :, slot_idx][slot_mask] = rand_vals[slot_mask]\n",
        "\n",
        "        # ì˜ˆì¸¡\n",
        "        with torch.no_grad():\n",
        "            pred = model(x_cat_perturbed.to(device), x_cont.to(device), mask.to(device)).cpu().numpy()\n",
        "\n",
        "        # RMSE ë³€í™”ëŸ‰ ì €ì¥\n",
        "        perturbed_rmse = np.sqrt(((y_true - pred) ** 2).mean())\n",
        "        delta = perturbed_rmse - base_rmse\n",
        "        slot_importance[slot] = delta\n",
        "\n",
        "    return sorted(slot_importance.items(), key=lambda x: -x[1])"
      ],
      "metadata": {
        "id": "r9HTYjgTj4SR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì¥ë¹„ ë¶€ìœ„ ì¤‘ìš”ë„ ê³„ì‚°\n",
        "slot_scores = compute_slot_importance(\n",
        "    model=model,\n",
        "    x_cat=x_cat,\n",
        "    x_cont=x_cont_with_count,\n",
        "    mask=mask,\n",
        "    y=y,\n",
        "    cat_cols=cat_cols,\n",
        "    equipment_slot_col='equipment_slot'\n",
        ")\n",
        "\n",
        "# equipment_slot ì¸ì½”ë”ë¡œ ë””ì½”ë”©\n",
        "equipment_slot_encoder = encoders['equipment_slot']\n",
        "decoded_scores = [(equipment_slot_encoder.inverse_transform([slot])[0], delta) for slot, delta in slot_scores]\n",
        "\n",
        "# ìƒìœ„ Top-N ì¶œë ¥\n",
        "top_n = 10\n",
        "for i, (slot_name, delta) in enumerate(decoded_scores[:top_n]):\n",
        "    print(f\"{i+1}. {slot_name} âœ ì „íˆ¬ë ¥ ì˜ˆì¸¡ RMSE ë³€í™”ëŸ‰: {delta:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeTwB6T5j4Pu",
        "outputId": "be5de42b-ca03-4847-c233-756a9a7f9607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ğŸ“Š ì¥ë¹„ ì¤‘ìš”ë„ ë¶„ì„ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:40<00:00,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. ë¬´ê¸° âœ ì „íˆ¬ë ¥ ì˜ˆì¸¡ RMSE ë³€í™”ëŸ‰: 5.0923\n",
            "2. ë±ƒì§€ âœ ì „íˆ¬ë ¥ ì˜ˆì¸¡ RMSE ë³€í™”ëŸ‰: 0.2533\n",
            "3. ëª¨ì âœ ì „íˆ¬ë ¥ ì˜ˆì¸¡ RMSE ë³€í™”ëŸ‰: 0.1940\n",
            "4. í›ˆì¥ âœ ì „íˆ¬ë ¥ ì˜ˆì¸¡ RMSE ë³€í™”ëŸ‰: 0.1739\n",
            "5. í•˜ì˜ âœ ì „íˆ¬ë ¥ ì˜ˆì¸¡ RMSE ë³€í™”ëŸ‰: 0.1460\n",
            "6. ì‹ ë°œ âœ ì „íˆ¬ë ¥ ì˜ˆì¸¡ RMSE ë³€í™”ëŸ‰: 0.1455\n",
            "7. ì¥ê°‘ âœ ì „íˆ¬ë ¥ ì˜ˆì¸¡ RMSE ë³€í™”ëŸ‰: 0.1450\n",
            "8. ë§í†  âœ ì „íˆ¬ë ¥ ì˜ˆì¸¡ RMSE ë³€í™”ëŸ‰: 0.1434\n",
            "9. ì–´ê¹¨ì¥ì‹ âœ ì „íˆ¬ë ¥ ì˜ˆì¸¡ RMSE ë³€í™”ëŸ‰: 0.1300\n",
            "10. í¬ì¼“ ì•„ì´í…œ âœ ì „íˆ¬ë ¥ ì˜ˆì¸¡ RMSE ë³€í™”ëŸ‰: 0.1274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì¤‘ìš”ë„ Top 3 (ë¬´ê¸°, ë±ƒì§€, ëª¨ì) ë§Œ ì‚¬ìš©í•œ ê²½ëŸ‰ ëª¨ë¸ êµ¬ì¶• ë° ì‹¤í—˜"
      ],
      "metadata": {
        "id": "rzYSYMw5nC6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì„¤ì •\n",
        "top_slots = ['ë¬´ê¸°', 'ë±ƒì§€', 'ëª¨ì']\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/item_nomissingvalues_copy.csv', na_values=[], keep_default_na=False)\n",
        "df_stat = pd.read_csv('/content/drive/MyDrive/data/merged/stat_merged.csv')\n",
        "df_stat_trimmed = df_stat[['nickname', 'subclass', 'ì „íˆ¬ë ¥']].drop_duplicates()\n",
        "df = df.merge(df_stat_trimmed, on=['nickname', 'subclass'], how='left')\n",
        "df.dropna(subset=['ì „íˆ¬ë ¥'], inplace=True)\n",
        "\n",
        "# Top-3 ì¥ë¹„ë§Œ í•„í„°ë§\n",
        "df = df[df['equipment_slot'].isin(top_slots)].copy()\n",
        "\n",
        "# ì „ì²˜ë¦¬\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "df = df.dropna(subset=cat_cols + num_cols + ['ì „íˆ¬ë ¥'])\n",
        "encoders = {col: LabelEncoder().fit(df[col]) for col in cat_cols}\n",
        "for col in cat_cols:\n",
        "    df[col] = encoders[col].transform(df[col])\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "df['log_ì „íˆ¬ë ¥'] = np.log1p(df['ì „íˆ¬ë ¥'])\n",
        "\n",
        "# ì‹œí€€ìŠ¤ êµ¬ì„±\n",
        "max_len = 3  # ì¥ë¹„ ê°œìˆ˜ (ë¬´ê¸°, ë±ƒì§€, ëª¨ì)\n",
        "df = df.sort_values(\"nickname\")\n",
        "\n",
        "x_cat_list, x_cont_list, mask_list, y_list = [], [], [], []\n",
        "\n",
        "for name, group in df.groupby(\"nickname\"):\n",
        "    cat = group[cat_cols].values.astype(np.int64)\n",
        "    cont = group[num_cols].values.astype(np.float32)\n",
        "    valid_len = len(group)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        pad_cat = np.zeros((max_len - valid_len, len(cat_cols)))\n",
        "        pad_cont = np.zeros((max_len - valid_len, len(num_cols)))\n",
        "        pad_mask = [0] * (max_len - valid_len)\n",
        "        cat = np.vstack([cat, pad_cat])\n",
        "        cont = np.vstack([cont, pad_cont])\n",
        "        mask = [1] * valid_len + pad_mask\n",
        "    else:\n",
        "        cat = cat[:max_len]\n",
        "        cont = cont[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    x_cat_list.append(torch.tensor(cat, dtype=torch.long))\n",
        "    x_cont_list.append(torch.tensor(cont, dtype=torch.float32))\n",
        "    mask_list.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    y_list.append(np.log1p(group['ì „íˆ¬ë ¥'].iloc[0]))\n",
        "\n",
        "x_cat = torch.stack(x_cat_list)\n",
        "x_cont = torch.stack(x_cont_list)\n",
        "mask = torch.stack(mask_list)\n",
        "y = torch.tensor(y_list, dtype=torch.float32)\n",
        "\n",
        "equip_counts = mask.sum(dim=1).unsqueeze(1).repeat(1, x_cont.shape[1]).unsqueeze(2)\n",
        "x_cont_with_count = torch.cat([x_cont, equip_counts], dim=2)\n",
        "embedding_info = {col: df[col].nunique() for col in cat_cols}"
      ],
      "metadata": {
        "id": "-Hn0BU-ej4M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# ëª¨ë¸ ì •ì˜ (ê¸°ì¡´ êµ¬ì¡° ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš©)\n",
        "class DeepMaskedModel(nn.Module):\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def _embed(self, x_cat):\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        return torch.cat(embs, dim=-1)\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        emb_cat = self._embed(x_cat)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        encoded = self.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "        return self.rho(pooled).squeeze()\n",
        "\n",
        "# 5-Fold í•™ìŠµ ë° í‰ê°€\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmses = []\n",
        "r2s = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(x_cat)):\n",
        "    print(f\"\\nğŸ“‚ Fold {fold + 1}\")\n",
        "\n",
        "    train_set = TensorDataset(x_cat[train_idx], x_cont_with_count[train_idx], mask[train_idx], y[train_idx])\n",
        "    val_set = TensorDataset(x_cat[val_idx], x_cont_with_count[val_idx], mask[val_idx], y[val_idx])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=256, shuffle=False)\n",
        "\n",
        "    model = DeepMaskedModel(embedding_info, x_cont_with_count.shape[-1]).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb.to(device), xfb.to(device), mb.to(device))\n",
        "            loss = criterion(preds, yb.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader.dataset):.4f}\")\n",
        "\n",
        "    # Fine-tune: ì˜ˆì¸¡ ì˜¤ì°¨ ìƒìœ„ 30%\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred_all = model(x_cat.to(device), x_cont_with_count.to(device), mask.to(device)).cpu().numpy()\n",
        "        y_all = y.numpy()\n",
        "    abs_errors = np.abs(pred_all - y_all)\n",
        "    threshold = np.percentile(abs_errors, 70)\n",
        "    error_indices = np.where(abs_errors > threshold)[0]\n",
        "\n",
        "    ft_set = TensorDataset(\n",
        "        x_cat[error_indices], x_cont_with_count[error_indices], mask[error_indices], y[error_indices]\n",
        "    )\n",
        "    ft_loader = DataLoader(ft_set, batch_size=32, shuffle=True)\n",
        "\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    for epoch in range(3):\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in ft_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb.to(device), xfb.to(device), mb.to(device))\n",
        "            loss = criterion(preds, yb.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"ğŸ”§ Fine-tune Epoch {epoch+1}: Loss = {total_loss / len(ft_loader.dataset):.4f}\")\n",
        "\n",
        "    # í‰ê°€\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        final_pred = model(x_cat.to(device), x_cont_with_count.to(device), mask.to(device)).cpu().numpy()\n",
        "    final_rmse = np.sqrt(mean_squared_error(y_all, final_pred))\n",
        "    final_r2 = r2_score(y_all, final_pred)\n",
        "    print(f\"âœ… Fold {fold+1} Final RMSE: {final_rmse:,.2f}, RÂ²: {final_r2:.4f}\")\n",
        "    rmses.append(final_rmse)\n",
        "    r2s.append(final_r2)\n",
        "\n",
        "# ìµœì¢… ì„±ëŠ¥\n",
        "print(f\"\\n Top-3 ì¥ë¹„ ê¸°ë°˜ í‰ê·  ì„±ëŠ¥: RMSE = {np.mean(rmses):,.2f}, RÂ² = {np.mean(r2s):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nSW13mErj4Js",
        "outputId": "c02d4598-6c0e-4e06-c155-29606b626ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“‚ Fold 1\n",
            "Epoch 1: Loss = 10.3448\n",
            "Epoch 2: Loss = 0.5981\n",
            "Epoch 3: Loss = 0.5621\n",
            "Epoch 4: Loss = 0.5551\n",
            "Epoch 5: Loss = 0.5630\n",
            "Epoch 6: Loss = 0.5667\n",
            "Epoch 7: Loss = 0.5554\n",
            "Epoch 8: Loss = 0.5606\n",
            "Epoch 9: Loss = 0.5485\n",
            "Epoch 10: Loss = 0.5381\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.3257\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.2987\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.2880\n",
            "âœ… Fold 1 Final RMSE: 0.86, RÂ²: 0.5394\n",
            "\n",
            "ğŸ“‚ Fold 2\n",
            "Epoch 1: Loss = 8.7736\n",
            "Epoch 2: Loss = 0.6277\n",
            "Epoch 3: Loss = 0.5846\n",
            "Epoch 4: Loss = 0.5818\n",
            "Epoch 5: Loss = 0.5789\n",
            "Epoch 6: Loss = 0.5630\n",
            "Epoch 7: Loss = 0.5674\n",
            "Epoch 8: Loss = 0.5500\n",
            "Epoch 9: Loss = 0.5501\n",
            "Epoch 10: Loss = 0.5539\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.3338\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.3002\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.2948\n",
            "âœ… Fold 2 Final RMSE: 0.79, RÂ²: 0.6108\n",
            "\n",
            "ğŸ“‚ Fold 3\n",
            "Epoch 1: Loss = 8.3407\n",
            "Epoch 2: Loss = 0.6105\n",
            "Epoch 3: Loss = 0.5752\n",
            "Epoch 4: Loss = 0.5794\n",
            "Epoch 5: Loss = 0.5650\n",
            "Epoch 6: Loss = 0.5713\n",
            "Epoch 7: Loss = 0.5651\n",
            "Epoch 8: Loss = 0.5648\n",
            "Epoch 9: Loss = 0.5433\n",
            "Epoch 10: Loss = 0.5420\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.3728\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.3455\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.3268\n",
            "âœ… Fold 3 Final RMSE: 0.81, RÂ²: 0.5874\n",
            "\n",
            "ğŸ“‚ Fold 4\n",
            "Epoch 1: Loss = 10.2369\n",
            "Epoch 2: Loss = 0.6033\n",
            "Epoch 3: Loss = 0.5690\n",
            "Epoch 4: Loss = 0.5675\n",
            "Epoch 5: Loss = 0.5516\n",
            "Epoch 6: Loss = 0.5662\n",
            "Epoch 7: Loss = 0.5597\n",
            "Epoch 8: Loss = 0.5551\n",
            "Epoch 9: Loss = 0.5423\n",
            "Epoch 10: Loss = 0.5425\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.3869\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.3696\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.3571\n",
            "âœ… Fold 4 Final RMSE: 0.78, RÂ²: 0.6159\n",
            "\n",
            "ğŸ“‚ Fold 5\n",
            "Epoch 1: Loss = 9.1725\n",
            "Epoch 2: Loss = 0.6389\n",
            "Epoch 3: Loss = 0.6039\n",
            "Epoch 4: Loss = 0.6019\n",
            "Epoch 5: Loss = 0.5982\n",
            "Epoch 6: Loss = 0.5841\n",
            "Epoch 7: Loss = 0.5951\n",
            "Epoch 8: Loss = 0.5903\n",
            "Epoch 9: Loss = 0.5902\n",
            "Epoch 10: Loss = 0.5685\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.1847\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.1628\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.1564\n",
            "âœ… Fold 5 Final RMSE: 0.85, RÂ²: 0.5468\n",
            "\n",
            " Top-3 ì¥ë¹„ ê¸°ë°˜ í‰ê·  ì„±ëŠ¥: RMSE = 0.82, RÂ² = 0.5801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì¤‘ìš”ë„ Top 5 (ë¬´ê¸°, ë±ƒì§€, ëª¨ì, í›ˆì¥, ì¥ê°‘) ë§Œ ì‚¬ìš©í•œ ê²½ëŸ‰ ëª¨ë¸ êµ¬ì¶• ë° ì‹¤í—˜"
      ],
      "metadata": {
        "id": "zaGyFFLZXOkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# ì„¤ì •\n",
        "top_5_slots = ['ë¬´ê¸°', 'ë±ƒì§€', 'ëª¨ì', 'í›ˆì¥', 'ì¥ê°‘']\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/item_nomissingvalues_copy.csv', na_values=[], keep_default_na=False)\n",
        "df_stat = pd.read_csv('/content/drive/MyDrive/data/merged/stat_merged.csv')\n",
        "df_stat_trimmed = df_stat[['nickname', 'subclass', 'ì „íˆ¬ë ¥']].drop_duplicates()\n",
        "df = df.merge(df_stat_trimmed, on=['nickname', 'subclass'], how='left')\n",
        "df.dropna(subset=['ì „íˆ¬ë ¥'], inplace=True)\n",
        "\n",
        "# Top-5 ì¥ë¹„ë§Œ í•„í„°ë§\n",
        "df = df[df['equipment_slot'].isin(top_5_slots)].copy()\n",
        "\n",
        "# ì „ì²˜ë¦¬\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "df = df.dropna(subset=cat_cols + num_cols + ['ì „íˆ¬ë ¥'])\n",
        "encoders = {col: LabelEncoder().fit(df[col]) for col in cat_cols}\n",
        "for col in cat_cols:\n",
        "    df[col] = encoders[col].transform(df[col])\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "df['log_ì „íˆ¬ë ¥'] = np.log1p(df['ì „íˆ¬ë ¥'])\n",
        "\n",
        "# ì‹œí€€ìŠ¤ êµ¬ì„±\n",
        "max_len = 5  # ì¥ë¹„ ê°œìˆ˜\n",
        "df = df.sort_values(\"nickname\")\n",
        "\n",
        "x_cat_list, x_cont_list, mask_list, y_list = [], [], [], []\n",
        "\n",
        "for name, group in df.groupby(\"nickname\"):\n",
        "    cat = group[cat_cols].values.astype(np.int64)\n",
        "    cont = group[num_cols].values.astype(np.float32)\n",
        "    valid_len = len(group)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        pad_cat = np.zeros((max_len - valid_len, len(cat_cols)))\n",
        "        pad_cont = np.zeros((max_len - valid_len, len(num_cols)))\n",
        "        pad_mask = [0] * (max_len - valid_len)\n",
        "        cat = np.vstack([cat, pad_cat])\n",
        "        cont = np.vstack([cont, pad_cont])\n",
        "        mask = [1] * valid_len + pad_mask\n",
        "    else:\n",
        "        cat = cat[:max_len]\n",
        "        cont = cont[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    x_cat_list.append(torch.tensor(cat, dtype=torch.long))\n",
        "    x_cont_list.append(torch.tensor(cont, dtype=torch.float32))\n",
        "    mask_list.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    y_list.append(np.log1p(group['ì „íˆ¬ë ¥'].iloc[0]))\n",
        "\n",
        "x_cat = torch.stack(x_cat_list)\n",
        "x_cont = torch.stack(x_cont_list)\n",
        "mask = torch.stack(mask_list)\n",
        "y = torch.tensor(y_list, dtype=torch.float32)\n",
        "\n",
        "equip_counts = mask.sum(dim=1).unsqueeze(1).repeat(1, x_cont.shape[1]).unsqueeze(2)\n",
        "x_cont_with_count = torch.cat([x_cont, equip_counts], dim=2)\n",
        "embedding_info = {col: df[col].nunique() for col in cat_cols}"
      ],
      "metadata": {
        "id": "gLupb9Voj4Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# ëª¨ë¸ ì •ì˜ (ê¸°ì¡´ êµ¬ì¡° ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš©)\n",
        "class DeepMaskedModel(nn.Module):\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def _embed(self, x_cat):\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        return torch.cat(embs, dim=-1)\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        emb_cat = self._embed(x_cat)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        encoded = self.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "        return self.rho(pooled).squeeze()\n",
        "\n",
        "# 5-Fold í•™ìŠµ ë° í‰ê°€\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmses = []\n",
        "r2s = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(x_cat)):\n",
        "    print(f\"\\nğŸ“‚ Fold {fold + 1}\")\n",
        "\n",
        "    train_set = TensorDataset(x_cat[train_idx], x_cont_with_count[train_idx], mask[train_idx], y[train_idx])\n",
        "    val_set = TensorDataset(x_cat[val_idx], x_cont_with_count[val_idx], mask[val_idx], y[val_idx])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=256, shuffle=False)\n",
        "\n",
        "    model = DeepMaskedModel(embedding_info, x_cont_with_count.shape[-1]).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb.to(device), xfb.to(device), mb.to(device))\n",
        "            loss = criterion(preds, yb.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader.dataset):.4f}\")\n",
        "\n",
        "    # Fine-tune: ì˜ˆì¸¡ ì˜¤ì°¨ ìƒìœ„ 30%\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred_all = model(x_cat.to(device), x_cont_with_count.to(device), mask.to(device)).cpu().numpy()\n",
        "        y_all = y.numpy()\n",
        "    abs_errors = np.abs(pred_all - y_all)\n",
        "    threshold = np.percentile(abs_errors, 70)\n",
        "    error_indices = np.where(abs_errors > threshold)[0]\n",
        "\n",
        "    ft_set = TensorDataset(\n",
        "        x_cat[error_indices], x_cont_with_count[error_indices], mask[error_indices], y[error_indices]\n",
        "    )\n",
        "    ft_loader = DataLoader(ft_set, batch_size=32, shuffle=True)\n",
        "\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    for epoch in range(3):\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in ft_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb.to(device), xfb.to(device), mb.to(device))\n",
        "            loss = criterion(preds, yb.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"ğŸ”§ Fine-tune Epoch {epoch+1}: Loss = {total_loss / len(ft_loader.dataset):.4f}\")\n",
        "\n",
        "    # í‰ê°€\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        final_pred = model(x_cat.to(device), x_cont_with_count.to(device), mask.to(device)).cpu().numpy()\n",
        "    final_rmse = np.sqrt(mean_squared_error(y_all, final_pred))\n",
        "    final_r2 = r2_score(y_all, final_pred)\n",
        "    print(f\"âœ… Fold {fold+1} Final RMSE: {final_rmse:,.2f}, RÂ²: {final_r2:.4f}\")\n",
        "    rmses.append(final_rmse)\n",
        "    r2s.append(final_r2)\n",
        "\n",
        "# ìµœì¢… ì„±ëŠ¥\n",
        "print(f\"\\n Top-5 ì¥ë¹„ ê¸°ë°˜ í‰ê·  ì„±ëŠ¥: RMSE = {np.mean(rmses):,.2f}, RÂ² = {np.mean(r2s):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kva4Rn0bj4D8",
        "outputId": "722d136c-4069-441a-ef41-72e85c21f268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“‚ Fold 1\n",
            "Epoch 1: Loss = 8.2146\n",
            "Epoch 2: Loss = 0.7032\n",
            "Epoch 3: Loss = 0.5847\n",
            "Epoch 4: Loss = 0.5602\n",
            "Epoch 5: Loss = 0.5450\n",
            "Epoch 6: Loss = 0.5460\n",
            "Epoch 7: Loss = 0.5583\n",
            "Epoch 8: Loss = 0.5517\n",
            "Epoch 9: Loss = 0.5293\n",
            "Epoch 10: Loss = 0.5296\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.3020\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.2799\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.2626\n",
            "âœ… Fold 1 Final RMSE: 0.75, RÂ²: 0.6493\n",
            "\n",
            "ğŸ“‚ Fold 2\n",
            "Epoch 1: Loss = 8.4987\n",
            "Epoch 2: Loss = 0.6026\n",
            "Epoch 3: Loss = 0.5527\n",
            "Epoch 4: Loss = 0.5299\n",
            "Epoch 5: Loss = 0.5319\n",
            "Epoch 6: Loss = 0.5229\n",
            "Epoch 7: Loss = 0.5277\n",
            "Epoch 8: Loss = 0.5118\n",
            "Epoch 9: Loss = 0.4880\n",
            "Epoch 10: Loss = 0.5087\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.3041\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.2635\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.2449\n",
            "âœ… Fold 2 Final RMSE: 0.70, RÂ²: 0.6969\n",
            "\n",
            "ğŸ“‚ Fold 3\n",
            "Epoch 1: Loss = 7.2001\n",
            "Epoch 2: Loss = 0.6577\n",
            "Epoch 3: Loss = 0.5735\n",
            "Epoch 4: Loss = 0.5499\n",
            "Epoch 5: Loss = 0.5594\n",
            "Epoch 6: Loss = 0.5455\n",
            "Epoch 7: Loss = 0.5395\n",
            "Epoch 8: Loss = 0.5342\n",
            "Epoch 9: Loss = 0.5315\n",
            "Epoch 10: Loss = 0.5072\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.1451\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.1300\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.1112\n",
            "âœ… Fold 3 Final RMSE: 0.79, RÂ²: 0.6109\n",
            "\n",
            "ğŸ“‚ Fold 4\n",
            "Epoch 1: Loss = 9.3789\n",
            "Epoch 2: Loss = 0.6701\n",
            "Epoch 3: Loss = 0.5905\n",
            "Epoch 4: Loss = 0.5754\n",
            "Epoch 5: Loss = 0.5646\n",
            "Epoch 6: Loss = 0.5620\n",
            "Epoch 7: Loss = 0.5501\n",
            "Epoch 8: Loss = 0.5589\n",
            "Epoch 9: Loss = 0.5438\n",
            "Epoch 10: Loss = 0.5388\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.4358\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.3927\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.3830\n",
            "âœ… Fold 4 Final RMSE: 0.71, RÂ²: 0.6870\n",
            "\n",
            "ğŸ“‚ Fold 5\n",
            "Epoch 1: Loss = 9.0001\n",
            "Epoch 2: Loss = 0.6621\n",
            "Epoch 3: Loss = 0.5742\n",
            "Epoch 4: Loss = 0.5612\n",
            "Epoch 5: Loss = 0.5476\n",
            "Epoch 6: Loss = 0.5512\n",
            "Epoch 7: Loss = 0.5518\n",
            "Epoch 8: Loss = 0.5488\n",
            "Epoch 9: Loss = 0.5320\n",
            "Epoch 10: Loss = 0.5235\n",
            "ğŸ”§ Fine-tune Epoch 1: Loss = 1.4255\n",
            "ğŸ”§ Fine-tune Epoch 2: Loss = 1.3990\n",
            "ğŸ”§ Fine-tune Epoch 3: Loss = 1.3848\n",
            "âœ… Fold 5 Final RMSE: 0.71, RÂ²: 0.6916\n",
            "\n",
            " Top-5 ì¥ë¹„ ê¸°ë°˜ í‰ê·  ì„±ëŠ¥: RMSE = 0.73, RÂ² = 0.6671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ìœ ì‚¬ ìœ ì € ì¶”ì²œ"
      ],
      "metadata": {
        "id": "KEiZKRz4r6vK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# phi(x) ë²¡í„° ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜\n",
        "def extract_user_vector(model, x_cat, x_cont, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        emb_cat = model._embed(x_cat)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        encoded = model.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "    return pooled.cpu().numpy()"
      ],
      "metadata": {
        "id": "KubMXvv5j38d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ê³ ë ˆë²¨ ìœ ì € ë²¡í„° ìƒì„± & ì €ì¥\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# ê³ ë ˆë²¨ ìœ ì € ê¸°ì¤€: ì „íˆ¬ë ¥ ìƒìœ„ 30% ë“±\n",
        "high_power_idx = np.argsort(-y.numpy())[:int(len(y) * 0.3)]\n",
        "\n",
        "# ë²¡í„° ìƒì„±\n",
        "model.eval()\n",
        "hl_vecs = []\n",
        "hl_nicks = []\n",
        "\n",
        "for i in high_power_idx:\n",
        "    vec = extract_user_vector(\n",
        "        model,\n",
        "        x_cat[i:i+1].to(device),\n",
        "        x_cont_with_count[i:i+1].to(device),\n",
        "        mask[i:i+1].to(device)\n",
        "    )[0]\n",
        "    hl_vecs.append(vec)\n",
        "    hl_nicks.append(df[df['nickname'] == df['nickname'].unique()[i]]['nickname'].iloc[0])\n",
        "\n",
        "hl_vecs = np.stack(hl_vecs)\n",
        "hl_nicks = np.array(hl_nicks)\n",
        "\n",
        "# ì €ì¥\n",
        "np.save(\"high_level_user_vectors.npy\", hl_vecs)\n",
        "np.save(\"high_level_user_nicks.npy\", hl_nicks)"
      ],
      "metadata": {
        "id": "0LpkxIO1pufM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì§ì—… ê¸°ë°˜ í‰ê· ê°’ ì‚¬ì „ êµ¬ì¶• -> ìœ ì €ê°€ ì •ë³´ë¥¼ ì…ë ¥í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ë„ ìë™ìœ¼ë¡œ ì±„ì›Œì¤„ ìˆ˜ ìˆê²Œë”\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# ëª¨ë“  ì¸ì½”ë”© ì»¬ëŸ¼ ë””ì½”ë”© (ë²”ì£¼í˜•)\n",
        "df_decoded = df.copy()\n",
        "for col in cat_cols:\n",
        "    if col in encoders:\n",
        "        df_decoded[col] = encoders[col].inverse_transform(df[col])\n",
        "\n",
        "# ì‚¬ì „ êµ¬ì¡° ì´ˆê¸°í™”\n",
        "subclass_profiles = defaultdict(lambda: defaultdict(dict))\n",
        "top_slots = ['ë¬´ê¸°', 'ëª¨ì', 'ì¥ê°‘'] # í›ˆì¥ê³¼ ë±ƒì§€ ì•„ì´í…œì˜ ê²½ìš°, ìœ ì €ë“¤ì˜ ë³„ë„ ê°•í™”ê°€ ë¶ˆê°€ëŠ¥í•œ ë¶€ìœ„ê¸° ë•Œë¬¸ì— ì œì™¸\n",
        "\n",
        "# ì‚¬ì „ êµ¬ì¶•\n",
        "for subclass in df_decoded['subclass'].unique():\n",
        "    for slot in top_slots:\n",
        "        # í•´ë‹¹ ì§ì—…-ë¶€ìœ„ ë°ì´í„° í•„í„°ë§\n",
        "        filtered = df_decoded[\n",
        "            (df_decoded['subclass'] == subclass) &\n",
        "            (df_decoded['equipment_slot'] == slot)\n",
        "        ]\n",
        "        if filtered.empty:\n",
        "            continue\n",
        "\n",
        "        # ë²”ì£¼í˜•: ìµœë¹ˆê°’ ì €ì¥ (ë””ì½”ë”©ëœ ìƒíƒœ)\n",
        "        for col in cat_cols:\n",
        "            try:\n",
        "                mode_val = filtered[col].mode(dropna=True)\n",
        "                if not mode_val.empty:\n",
        "                    subclass_profiles[subclass][slot][col] = mode_val.iloc[0]\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        # ìˆ˜ì¹˜í˜•: ì •ê·œí™”ëœ í‰ê· ê°’ â†’ ì›ë˜ ìŠ¤ì¼€ì¼ë¡œ ì—­ë³€í™˜ í›„ ì €ì¥\n",
        "        for col in num_cols:\n",
        "            try:\n",
        "                mean_val = filtered[col].mean()\n",
        "                if np.isnan(mean_val):\n",
        "                    continue\n",
        "                col_index = num_cols.index(col)\n",
        "                dummy_vec = np.zeros(len(num_cols))\n",
        "                dummy_vec[col_index] = mean_val\n",
        "                original_val = scaler.inverse_transform([dummy_vec])[0][col_index]\n",
        "                subclass_profiles[subclass][slot][col] = round(original_val, 2)\n",
        "            except:\n",
        "                continue"
      ],
      "metadata": {
        "id": "3YBF9S-i8AGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì‚¬ìš© ì˜ˆì‹œ: ë‚˜ì´íŠ¸ë¡œë“œ ìœ ì €ê°€ ì¥ê°‘ ì •ë³´ ì…ë ¥ ì•ˆ í–ˆì„ ë•Œ\n",
        "slot_profile = subclass_profiles['ë‚˜ì´íŠ¸ë¡œë“œ']['ì¥ê°‘']\n",
        "\n",
        "print(\"ğŸ”¹ ì£¼ìŠ¤íƒ¯ ìœ í˜•:\", slot_profile.get('main_stat_type', 'N/A'))\n",
        "print(\"ğŸ”¹ ìŠ¤íƒ€í¬ìŠ¤ í‰ê· :\", slot_profile.get('starforce', 'N/A'))\n",
        "print(\"ğŸ”¹ ì¥ë¹„ ì„¸íŠ¸:\", slot_profile.get('item_group', 'N/A'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP3-EbbA8ACz",
        "outputId": "75b89d85-e0ae-4547-d4f1-d70643b79d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”¹ ì£¼ìŠ¤íƒ¯ ìœ í˜•: LUK\n",
            "ğŸ”¹ ìŠ¤íƒ€í¬ìŠ¤ í‰ê· : 20.8\n",
            "ğŸ”¹ ì¥ë¹„ ì„¸íŠ¸: ì•„ì¼€ì¸ì…°ì´ë“œ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì§ì—… ê¸°ë°˜ í‰ê· ê°’ -> ì €ì¥ ì½”ë“œ\n",
        "import pickle\n",
        "\n",
        "with open(\"subclass_profiles.pkl\", \"wb\") as f:\n",
        "    pickle.dump(dict(subclass_profiles), f)  # defaultdictëŠ” dictë¡œ ë³€í™˜í•´ì„œ ì €ì¥"
      ],
      "metadata": {
        "id": "HQMwCaHxCdkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì§ì—… ê¸°ë°˜ í‰ê· ê°’ -> ë¶ˆëŸ¬ì˜¤ê¸° ì½”ë“œ\n",
        "with open(\"subclass_profiles.pkl\", \"rb\") as f:\n",
        "    subclass_profiles = pickle.load(f)"
      ],
      "metadata": {
        "id": "acPa5VI2CdfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = {\n",
        "    'subclass': 'ì¹´ì¸',\n",
        "    'ë¬´ê¸°': {\n",
        "        'item_group': 'ë„ì „ì',       # ì¥ë¹„ ì„¸íŠ¸\n",
        "        'starforce': 15,              # ìŠ¤íƒ€í¬ìŠ¤ ê°•í™” ìˆ˜ì¹˜\n",
        "        'mainstat_total': 124,        # ì¥ë¹„ì— ë¶™ì€ ìµœì¢… ì£¼ìŠ¤íƒ¯\n",
        "        'power_total': 80,            # ì¥ë¹„ì— ë¶™ì€ ìµœì¢… ê³µê²©ë ¥/ë§ˆë ¥\n",
        "        'all_stat_total': 12,         # ì¥ë¹„ì— ë¶™ì€ ìµœì¢… ì˜¬ìŠ¤íƒ¯\n",
        "        'potential_option_grade': 'ìœ ë‹ˆí¬',            # ì ì¬ì˜µì…˜ ë“±ê¸‰\n",
        "        'additional_potential_option_grade': 'ì—í”½',   # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ ë“±ê¸‰\n",
        "        'potential_option_1_grade': 'S',               # ì ì¬ì˜µì…˜ 1ì˜ ë¶„ë¥˜\n",
        "        'potential_option_2_grade': 'S',               # ì ì¬ì˜µì…˜ 2ì˜ ë¶„ë¥˜\n",
        "        'potential_option_3_grade': 'B',               # ì ì¬ì˜µì…˜ 3ì˜ ë¶„ë¥˜\n",
        "        'additional_potential_option_1_grade': 'B',    # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ 1ì˜ ë¶„ë¥˜\n",
        "        'additional_potential_option_2_grade': 'ê¸°íƒ€', # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ 2ì˜ ë¶„ë¥˜\n",
        "        'additional_potential_option_3_grade': 'ê¸°íƒ€'  # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ 3ì˜ ë¶„ë¥˜\n",
        "},\n",
        "    'ëª¨ì': {\n",
        "        'item_group': 'íŒŒí”„ë‹ˆë¥´',       # ì¥ë¹„ ì„¸íŠ¸\n",
        "        'starforce': 20,                # ìŠ¤íƒ€í¬ìŠ¤ ê°•í™” ìˆ˜ì¹˜\n",
        "        'mainstat_total': 300,          # ì¥ë¹„ì— ë¶™ì€ ìµœì¢… ì£¼ìŠ¤íƒ¯\n",
        "        'power_total': 78,              # ì¥ë¹„ì— ë¶™ì€ ìµœì¢… ê³µê²©ë ¥/ë§ˆë ¥\n",
        "        'all_stat_total': 6,            # ì¥ë¹„ì— ë¶™ì€ ìµœì¢… ì˜¬ìŠ¤íƒ¯\n",
        "        'potential_option_grade': 'ë ˆì „ë“œë¦¬',          # ì ì¬ì˜µì…˜ ë“±ê¸‰\n",
        "        'additional_potential_option_grade': 'ì—í”½',   # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ ë“±ê¸‰\n",
        "        'potential_option_1_grade': 'S',               # ì ì¬ì˜µì…˜ 1ì˜ ë¶„ë¥˜\n",
        "        'potential_option_2_grade': 'S',               # ì ì¬ì˜µì…˜ 2ì˜ ë¶„ë¥˜\n",
        "        'potential_option_3_grade': 'S',               # ì ì¬ì˜µì…˜ 3ì˜ ë¶„ë¥˜\n",
        "        'additional_potential_option_1_grade': 'B',    # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ 1ì˜ ë¶„ë¥˜\n",
        "        'additional_potential_option_2_grade': 'ê¸°íƒ€', # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ 2ì˜ ë¶„ë¥˜\n",
        "        'additional_potential_option_3_grade': 'B'     # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ 3ì˜ ë¶„ë¥˜\n",
        "},\n",
        "    'ì¥ê°‘': {\n",
        "        'item_group': 'ì•±ì†”ë©ìŠ¤',       # ì¥ë¹„ ì„¸íŠ¸\n",
        "        'starforce': 18,                # ìŠ¤íƒ€í¬ìŠ¤ ê°•í™” ìˆ˜ì¹˜\n",
        "        'mainstat_total': 100,          # ì¥ë¹„ì— ë¶™ì€ ìµœì¢… ì£¼ìŠ¤íƒ¯\n",
        "        'power_total': 70,              # ì¥ë¹„ì— ë¶™ì€ ìµœì¢… ê³µê²©ë ¥/ë§ˆë ¥\n",
        "        'all_stat_total': 0,            # ì¥ë¹„ì— ë¶™ì€ ìµœì¢… ì˜¬ìŠ¤íƒ¯\n",
        "        'potential_option_grade': 'ìœ ë‹ˆí¬',            # ì ì¬ì˜µì…˜ ë“±ê¸‰\n",
        "        'additional_potential_option_grade': 'ì—í”½',   # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ ë“±ê¸‰\n",
        "        'potential_option_1_grade': 'S',               # ì ì¬ì˜µì…˜ 1ì˜ ë¶„ë¥˜\n",
        "        'potential_option_2_grade': 'S',               # ì ì¬ì˜µì…˜ 2ì˜ ë¶„ë¥˜\n",
        "        'potential_option_3_grade': 'ê¸°íƒ€',            # ì ì¬ì˜µì…˜ 3ì˜ ë¶„ë¥˜\n",
        "        'additional_potential_option_1_grade': 'S',    # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ 1ì˜ ë¶„ë¥˜\n",
        "        'additional_potential_option_2_grade': 'S',    # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ 2ì˜ ë¶„ë¥˜\n",
        "        'additional_potential_option_3_grade': 'ê¸°íƒ€'  # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ 3ì˜ ë¶„ë¥˜\n",
        "}\n",
        "}"
      ],
      "metadata": {
        "id": "bsOEUKI6CdcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì¤‘ìš”ë„ ë†’ì€ ì•„ì´í…œ ì •ë³´ ì…ë ¥ ê¸°ë°˜ ìœ ì‚¬ ìœ ì € ì¶”ì²œ\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# ì§ì—…ë³„ ì£¼ìŠ¤íƒ¯ ë§¤í•‘\n",
        "main_stat_map = {\n",
        "    \"STR\": [\"íˆì–´ë¡œ\", \"ì•„ë¸\", \"ì†Œìš¸ë§ˆìŠ¤í„°\", \"ì•„ë€\", \"ì œë¡œ\", \"íŒ”ë¼ë”˜\", \"ë‹¤í¬ë‚˜ì´íŠ¸\", \"ì¹´ì´ì €\",\n",
        "            \"ë°ëª¬ìŠ¬ë ˆì´ì–´\", \"ë¯¸í•˜ì¼\", \"ë¸”ë˜ìŠ¤í„°\", \"ì€ì›”\", \"ë°”ì´í¼\", \"ìŠ¤íŠ¸ë¼ì´ì»¤\", \"ìºë…¼ë§ˆìŠ¤í„°\", \"ì•„í¬\"],\n",
        "    \"DEX\": [\"ìœˆë“œë¸Œë ˆì´ì»¤\", \"ë©”ë¥´ì„¸ë°ìŠ¤\", \"ë³´ìš°ë§ˆìŠ¤í„°\", \"íŒ¨ìŠ¤íŒŒì¸ë”\", \"ì‹ ê¶\", \"ì¹´ì¸\", \"ì™€ì¼ë“œí—Œí„°\",\n",
        "            \"ì—”ì ¤ë¦­ë²„ìŠ¤í„°\", \"ìº¡í‹´\", \"ë©”ì¹´ë‹‰\"],\n",
        "    \"INT\": [\"ë¹„ìˆ\", \"ì•„í¬ë©”ì´ì§€(ë¶ˆ,ë…)\", \"ì•„í¬ë©”ì´ì§€(ì¬,ì½œ)\", \"ë¼ë¼\", \"ë°°í‹€ë©”ì´ì§€\", \"ì—ë°˜\", \"ë£¨ë¯¸ë„ˆìŠ¤\",\n",
        "            \"í‚¤ë„¤ì‹œìŠ¤\", \"í”Œë ˆì„ìœ„ìë“œ\", \"ì¼ë¦¬ì›€\"],\n",
        "    \"LUK\": [\"ë‚˜ì´íŠ¸ì›Œì»¤\", \"ì„€ë„ì–´\", \"ë‚˜ì´íŠ¸ë¡œë“œ\", \"ë“€ì–¼ë¸”ë ˆì´ë”\", \"íŒ¬í…€\", \"í˜¸ì˜\", \"ì¹¼ë¦¬\", \"ì¹´ë°ë‚˜\"],\n",
        "    \"HP\": [\"ë°ëª¬ì–´ë²¤ì ¸\"],\n",
        "    \"STR_DEX_LUK\": [\"ì œë…¼\"]\n",
        "}\n",
        "\n",
        "def get_main_stat(subclass):\n",
        "    for stat, jobs in main_stat_map.items():\n",
        "        if subclass in jobs:\n",
        "            return stat\n",
        "    return \"ê¸°íƒ€\"\n",
        "\n",
        "# ì¥ë¹„ ì •ë³´ ìë™ ì±„ì›€\n",
        "def fill_missing_slots(user_input, subclass_profiles, top_slots):\n",
        "    subclass = user_input['subclass']\n",
        "    main_stat = get_main_stat(subclass)\n",
        "    filled = {}\n",
        "\n",
        "    for slot in top_slots:\n",
        "        if slot in user_input:\n",
        "            filled[slot] = user_input[slot]\n",
        "        else:\n",
        "            filled[slot] = subclass_profiles.get(subclass, {}).get(slot, {}).copy()\n",
        "\n",
        "        if 'main_stat_type' not in filled[slot] or filled[slot]['main_stat_type'] is None:\n",
        "            filled[slot]['main_stat_type'] = main_stat\n",
        "\n",
        "    return filled\n",
        "\n",
        "# ì¸ì½”ë”© + ìŠ¤ì¼€ì¼ë§ + í…ì„œ ë³€í™˜\n",
        "def encode_and_scale(filled_slots, subclass, encoders, scaler, cat_cols, num_cols):\n",
        "    x_cat_rows, x_cont_rows = [], []\n",
        "\n",
        "    for slot in filled_slots:\n",
        "        row_cat, row_cont = [], []\n",
        "\n",
        "        for col in cat_cols:\n",
        "            if col == 'subclass':\n",
        "                val = subclass\n",
        "            elif col == 'equipment_slot':\n",
        "                val = slot\n",
        "            else:\n",
        "                val = filled_slots[slot].get(col, subclass_profiles.get(subclass, {}).get(slot, {}).get(col, None))\n",
        "\n",
        "            if val is None:\n",
        "                val = encoders[col].classes_[0]\n",
        "            if isinstance(val, list):\n",
        "                val = '+'.join(val)\n",
        "            if val not in encoders[col].classes_:\n",
        "                val = encoders[col].classes_[0]\n",
        "\n",
        "            row_cat.append(encoders[col].transform([val])[0])\n",
        "\n",
        "        for col in num_cols:\n",
        "            val = filled_slots[slot].get(col, subclass_profiles.get(subclass, {}).get(slot, {}).get(col, 0.0))\n",
        "            row_cont.append(val)\n",
        "\n",
        "        x_cat_rows.append(row_cat)\n",
        "        x_cont_rows.append(row_cont)\n",
        "\n",
        "    x_cat_tensor = torch.tensor(x_cat_rows, dtype=torch.long).unsqueeze(0)\n",
        "    x_cont_tensor = torch.tensor(scaler.transform(x_cont_rows), dtype=torch.float32).unsqueeze(0)\n",
        "    mask_tensor = torch.tensor([[1] * len(filled_slots)], dtype=torch.float32)\n",
        "\n",
        "    equip_counts = mask_tensor.sum(dim=1, keepdim=True).repeat(1, x_cont_tensor.shape[1], 1)\n",
        "    x_cont_tensor = torch.cat([x_cont_tensor, equip_counts], dim=2)\n",
        "\n",
        "    return x_cat_tensor, x_cont_tensor, mask_tensor\n",
        "\n",
        "# phi(x) ë²¡í„° ì¶”ì¶œ\n",
        "def extract_user_vector(model, x_cat, x_cont, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        emb_cat = model._embed(x_cat.to(device))\n",
        "        x = torch.cat([emb_cat, x_cont.to(device)], dim=-1)\n",
        "        encoded = model.phi(x)\n",
        "        masked = encoded * mask.to(device).unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "    return pooled.cpu().numpy()[0]\n",
        "\n",
        "# ìœ ì‚¬ë„ ê³„ì‚° (subclass ë™ì¼í•œ ìœ ì €ë§Œ ëŒ€ìƒ)\n",
        "def recommend_similar_users(user_vec, hl_vecs, hl_nicks, df_stat_trimmed, target_subclass, top_k=5):\n",
        "    # subclass ê¸°ì¤€ í•„í„°ë§\n",
        "    nick_to_idx = {nick: i for i, nick in enumerate(hl_nicks)}\n",
        "    filtered_nicks = df_stat_trimmed[df_stat_trimmed['subclass'] == target_subclass]['nickname'].tolist()\n",
        "    valid_indices = [nick_to_idx[nick] for nick in filtered_nicks if nick in nick_to_idx]\n",
        "\n",
        "    hl_vecs_filtered = hl_vecs[valid_indices]\n",
        "    hl_nicks_filtered = [hl_nicks[i] for i in valid_indices]\n",
        "\n",
        "    # ìœ ì‚¬ë„ ê³„ì‚°\n",
        "    sims = cosine_similarity(user_vec.reshape(1, -1), hl_vecs_filtered).flatten()\n",
        "    top_idx = sims.argsort()[-top_k:][::-1]\n",
        "    return [(hl_nicks_filtered[i], sims[i]) for i in top_idx]\n",
        "\n",
        "# ğŸ”§ ì „ì²´ ì‹¤í–‰ ì˜ˆì‹œ íë¦„\n",
        "user_input = {\n",
        "    'subclass': 'ì¹´ì¸',\n",
        "    'ë¬´ê¸°': {\n",
        "        'item_group': 'ë„ì „ì',       # ì¥ë¹„ ì„¸íŠ¸\n",
        "        'starforce': 15,              # ìŠ¤íƒ€í¬ìŠ¤ ê°•í™” ìˆ˜ì¹˜\n",
        "        'mainstat_total': 124,        # ì¥ë¹„ì— ë¶™ì€ ìµœì¢… ì£¼ìŠ¤íƒ¯\n",
        "        'power_total': 80,            # ì¥ë¹„ì— ë¶™ì€ ìµœì¢… ê³µê²©ë ¥/ë§ˆë ¥\n",
        "        'all_stat_total': 12,         # ì¥ë¹„ì— ë¶™ì€ ìµœì¢… ì˜¬ìŠ¤íƒ¯\n",
        "        'potential_option_grade': 'ìœ ë‹ˆí¬',            # ì ì¬ì˜µì…˜ ë“±ê¸‰\n",
        "        'additional_potential_option_grade': 'ì—í”½',   # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ ë“±ê¸‰\n",
        "        'potential_option_1_grade': 'S',               # ì ì¬ì˜µì…˜ 1ì˜ ë¶„ë¥˜\n",
        "        'potential_option_2_grade': 'S',               # ì ì¬ì˜µì…˜ 2ì˜ ë¶„ë¥˜\n",
        "        'potential_option_3_grade': 'B',               # ì ì¬ì˜µì…˜ 3ì˜ ë¶„ë¥˜\n",
        "        'additional_potential_option_1_grade': 'B',    # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ 1ì˜ ë¶„ë¥˜\n",
        "        'additional_potential_option_2_grade': 'ê¸°íƒ€', # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ 2ì˜ ë¶„ë¥˜\n",
        "        'additional_potential_option_3_grade': 'ê¸°íƒ€'  # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ 3ì˜ ë¶„ë¥˜\n",
        "},\n",
        "    'ëª¨ì': {\n",
        "        'item_group': 'íŒŒí”„ë‹ˆë¥´',       # ì¥ë¹„ ì„¸íŠ¸\n",
        "        'starforce': 20,                # ìŠ¤íƒ€í¬ìŠ¤ ê°•í™” ìˆ˜ì¹˜\n",
        "        'mainstat_total': 300,          # ì¥ë¹„ì— ë¶™ì€ ìµœì¢… ì£¼ìŠ¤íƒ¯\n",
        "        'power_total': 78,              # ì¥ë¹„ì— ë¶™ì€ ìµœì¢… ê³µê²©ë ¥/ë§ˆë ¥\n",
        "        'all_stat_total': 6,            # ì¥ë¹„ì— ë¶™ì€ ìµœì¢… ì˜¬ìŠ¤íƒ¯\n",
        "        'potential_option_grade': 'ë ˆì „ë“œë¦¬',          # ì ì¬ì˜µì…˜ ë“±ê¸‰\n",
        "        'additional_potential_option_grade': 'ì—í”½',   # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ ë“±ê¸‰\n",
        "        'potential_option_1_grade': 'S',               # ì ì¬ì˜µì…˜ 1ì˜ ë¶„ë¥˜\n",
        "        'potential_option_2_grade': 'S',               # ì ì¬ì˜µì…˜ 2ì˜ ë¶„ë¥˜\n",
        "        'potential_option_3_grade': 'S',               # ì ì¬ì˜µì…˜ 3ì˜ ë¶„ë¥˜\n",
        "        'additional_potential_option_1_grade': 'B',    # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ 1ì˜ ë¶„ë¥˜\n",
        "        'additional_potential_option_2_grade': 'ê¸°íƒ€', # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ 2ì˜ ë¶„ë¥˜\n",
        "        'additional_potential_option_3_grade': 'B'     # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ 3ì˜ ë¶„ë¥˜\n",
        "},\n",
        "    'ì¥ê°‘': {\n",
        "        'item_group': 'ì•±ì†”ë©ìŠ¤',       # ì¥ë¹„ ì„¸íŠ¸\n",
        "        'starforce': 18,                # ìŠ¤íƒ€í¬ìŠ¤ ê°•í™” ìˆ˜ì¹˜\n",
        "        'mainstat_total': 100,          # ì¥ë¹„ì— ë¶™ì€ ìµœì¢… ì£¼ìŠ¤íƒ¯\n",
        "        'power_total': 70,              # ì¥ë¹„ì— ë¶™ì€ ìµœì¢… ê³µê²©ë ¥/ë§ˆë ¥\n",
        "        'all_stat_total': 0,            # ì¥ë¹„ì— ë¶™ì€ ìµœì¢… ì˜¬ìŠ¤íƒ¯\n",
        "        'potential_option_grade': 'ìœ ë‹ˆí¬',            # ì ì¬ì˜µì…˜ ë“±ê¸‰\n",
        "        'additional_potential_option_grade': 'ì—í”½',   # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ ë“±ê¸‰\n",
        "        'potential_option_1_grade': 'S',               # ì ì¬ì˜µì…˜ 1ì˜ ë¶„ë¥˜\n",
        "        'potential_option_2_grade': 'S',               # ì ì¬ì˜µì…˜ 2ì˜ ë¶„ë¥˜\n",
        "        'potential_option_3_grade': 'ê¸°íƒ€',            # ì ì¬ì˜µì…˜ 3ì˜ ë¶„ë¥˜\n",
        "        'additional_potential_option_1_grade': 'S',    # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ 1ì˜ ë¶„ë¥˜\n",
        "        'additional_potential_option_2_grade': 'S',    # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ 2ì˜ ë¶„ë¥˜\n",
        "        'additional_potential_option_3_grade': 'ê¸°íƒ€'  # ì—ë””ì…”ë„ ì ì¬ì˜µì…˜ 3ì˜ ë¶„ë¥˜\n",
        "}\n",
        "}\n",
        "\n",
        "top_slots = ['ë¬´ê¸°', 'ëª¨ì', 'ì¥ê°‘']\n",
        "\n",
        "filled = fill_missing_slots(user_input, subclass_profiles, top_slots)\n",
        "x_cat_new, x_cont_new, mask_new = encode_and_scale(\n",
        "    filled_slots=filled,\n",
        "    subclass=user_input['subclass'],\n",
        "    encoders=encoders,\n",
        "    scaler=scaler,\n",
        "    cat_cols=cat_cols,\n",
        "    num_cols=num_cols\n",
        ")\n",
        "\n",
        "user_vec = extract_user_vector(model, x_cat_new, x_cont_new, mask_new)\n",
        "\n",
        "# df_stat_trimmed = df_stat[['nickname', 'subclass']].drop_duplicates() ê°€ì •ë¨\n",
        "recommendations = recommend_similar_users(\n",
        "    user_vec=user_vec,\n",
        "    hl_vecs=hl_vecs,\n",
        "    hl_nicks=hl_nicks,\n",
        "    df_stat_trimmed=df_stat_trimmed,\n",
        "    target_subclass=user_input['subclass']\n",
        ")\n",
        "\n",
        "print(f\"\\nğŸ“Œ ì§ì—…: {user_input['subclass']}  |  ì£¼ìŠ¤íƒ¯: {get_main_stat(user_input['subclass'])}\")\n",
        "print(\"âœ¨ ìœ ì‚¬í•œ ê³ ë ˆë²¨ ìœ ì € ì¶”ì²œ âœ¨\\n\")\n",
        "for i, (nick, sim) in enumerate(recommendations, 1):\n",
        "    print(f\"{i}. ë‹‰ë„¤ì„: {nick}  |  ìœ ì‚¬ë„: {sim:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arOTR4KDlNu-",
        "outputId": "e5a5d833-5c42-4678-f3ff-28aa7133896b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Œ ì§ì—…: ì¹´ì¸  |  ì£¼ìŠ¤íƒ¯: DEX\n",
            "âœ¨ ìœ ì‚¬í•œ ê³ ë ˆë²¨ ìœ ì € ì¶”ì²œ âœ¨\n",
            "\n",
            "1. ë‹‰ë„¤ì„: ìƒŒí•‘  |  ìœ ì‚¬ë„: 0.9997\n",
            "2. ë‹‰ë„¤ì„: ê¹€ë§Œë–½  |  ìœ ì‚¬ë„: 0.9997\n",
            "3. ë‹‰ë„¤ì„: ê¾¸ìš´ê°ì  |  ìœ ì‚¬ë„: 0.9997\n",
            "4. ë‹‰ë„¤ì„: ì¹´ë§ê¹Œì§€  |  ìœ ì‚¬ë„: 0.9997\n",
            "5. ë‹‰ë„¤ì„: ë™ì–‘ì˜ì¸ì¬  |  ìœ ì‚¬ë„: 0.9997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top-3 ì¤‘ìš” ì¥ë¹„ ê¸°ë°˜ ì „íˆ¬ë ¥ ì˜ˆì¸¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ë¬´ê¸°, ëª¨ì, ì¥ê°‘)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# ì„¤ì •\n",
        "top_3_slots = ['ë¬´ê¸°', 'ëª¨ì', 'ì¥ê°‘']\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/item_nomissingvalues_copy.csv', na_values=[], keep_default_na=False)\n",
        "df_stat = pd.read_csv('/content/drive/MyDrive/data/merged/stat_merged.csv')\n",
        "df_stat_trimmed = df_stat[['nickname', 'subclass', 'ì „íˆ¬ë ¥']].drop_duplicates()\n",
        "df = df.merge(df_stat_trimmed, on=['nickname', 'subclass'], how='left')\n",
        "df.dropna(subset=['ì „íˆ¬ë ¥'], inplace=True)\n",
        "\n",
        "# ì „ì²˜ë¦¬\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "# Top-3 ì¥ë¹„ë§Œ í•„í„°ë§\n",
        "df = df[df['equipment_slot'].isin(top_3_slots)].copy()\n",
        "df = df.dropna(subset=cat_cols + num_cols + ['ì „íˆ¬ë ¥'])\n",
        "\n",
        "# ì¸ì½”ë”© ë° ìŠ¤ì¼€ì¼ë§\n",
        "encoders = {col: LabelEncoder().fit(df[col]) for col in cat_cols}\n",
        "for col in cat_cols:\n",
        "    df[col] = encoders[col].transform(df[col])\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "df['log_ì „íˆ¬ë ¥'] = np.log1p(df['ì „íˆ¬ë ¥'])\n",
        "\n",
        "# ì‹œí€€ìŠ¤ êµ¬ì„±\n",
        "max_len = len(top_3_slots)\n",
        "df = df.sort_values(\"nickname\")\n",
        "\n",
        "x_cat_list, x_cont_list, mask_list, y_list = [], [], [], []\n",
        "\n",
        "for name, group in df.groupby(\"nickname\"):\n",
        "    cat = group[cat_cols].values.astype(np.int64)\n",
        "    cont = group[num_cols].values.astype(np.float32)\n",
        "    valid_len = len(group)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        pad_cat = np.zeros((max_len - valid_len, len(cat_cols)))\n",
        "        pad_cont = np.zeros((max_len - valid_len, len(num_cols)))\n",
        "        pad_mask = [0] * (max_len - valid_len)\n",
        "        cat = np.vstack([cat, pad_cat])\n",
        "        cont = np.vstack([cont, pad_cont])\n",
        "        mask = [1] * valid_len + pad_mask\n",
        "    else:\n",
        "        cat = cat[:max_len]\n",
        "        cont = cont[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    x_cat_list.append(torch.tensor(cat, dtype=torch.long))\n",
        "    x_cont_list.append(torch.tensor(cont, dtype=torch.float32))\n",
        "    mask_list.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    y_list.append(np.log1p(group['ì „íˆ¬ë ¥'].iloc[0]))\n",
        "\n",
        "x_cat = torch.stack(x_cat_list)\n",
        "x_cont = torch.stack(x_cont_list)\n",
        "mask = torch.stack(mask_list)\n",
        "y = torch.tensor(y_list, dtype=torch.float32)\n",
        "\n",
        "# equip count ì¶”ê°€\n",
        "equip_counts = mask.sum(dim=1).unsqueeze(1).repeat(1, x_cont.shape[1]).unsqueeze(2)\n",
        "x_cont = torch.cat([x_cont, equip_counts], dim=2)\n",
        "\n",
        "embedding_info = {col: df[col].nunique() for col in cat_cols}\n",
        "\n",
        "# ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmses, r2s = [], []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(x_cat)):\n",
        "    model = DeepMaskedModel(embedding_info, x_cont.shape[-1])\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    train_set = torch.utils.data.TensorDataset(x_cat[train_idx], x_cont[train_idx], mask[train_idx], y[train_idx])\n",
        "    val_set = torch.utils.data.TensorDataset(x_cat[val_idx], x_cont[val_idx], mask[val_idx], y[val_idx])\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=256)\n",
        "\n",
        "    for epoch in range(5):\n",
        "        model.train()\n",
        "        for xc, xc2, m, yt in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(xc, xc2, m)\n",
        "            loss = criterion(pred, yt)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    preds, targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for xc, xc2, m, yt in val_loader:\n",
        "            pred = model(xc, xc2, m)\n",
        "            preds.append(pred.numpy())\n",
        "            targets.append(yt.numpy())\n",
        "\n",
        "    preds = np.concatenate(preds)\n",
        "    targets = np.concatenate(targets)\n",
        "    rmse = np.sqrt(mean_squared_error(targets, preds))\n",
        "    r2 = r2_score(targets, preds)\n",
        "    rmses.append(rmse)\n",
        "    r2s.append(r2)\n",
        "    print(f\"Fold {fold+1}: RMSE={rmse:.4f}, R2={r2:.4f}\")\n",
        "\n",
        "print(f\"\\nğŸ“Š ìµœì¢… í‰ê·  ì„±ëŠ¥ (ë¬´ê¸°+ëª¨ì+ì¥ê°‘): RMSE={np.mean(rmses):.4f}, R2={np.mean(r2s):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFT8GBF8uVL9",
        "outputId": "b985398d-0b4c-4e4e-ea38-0e39674a02bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: RMSE=0.5819, R2=0.5351\n",
            "Fold 2: RMSE=0.6507, R2=0.5182\n",
            "Fold 3: RMSE=0.5945, R2=0.6485\n",
            "Fold 4: RMSE=0.6057, R2=0.5964\n",
            "Fold 5: RMSE=0.5636, R2=0.7043\n",
            "\n",
            "ğŸ“Š ìµœì¢… í‰ê·  ì„±ëŠ¥ (ë¬´ê¸°+ëª¨ì+ì¥ê°‘): RMSE=0.5993, R2=0.6005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top-10 ì¤‘ìš” ì¥ë¹„ ê¸°ë°˜ ì „íˆ¬ë ¥ ì˜ˆì¸¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ë¬´ê¸°, ëª¨ì, í•˜ì˜, ì‹ ë°œ, ì¥ê°‘, ë§í† , ì–´ê¹¨ì¥ì‹)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# ì„¤ì •\n",
        "selected_slots = ['ë¬´ê¸°', 'ëª¨ì', 'í•˜ì˜', 'ì‹ ë°œ', 'ì¥ê°‘', 'ë§í† ', 'ì–´ê¹¨ì¥ì‹']\n",
        "selected_features = ['item_group', 'starforce', 'mainstat_total', 'power_total',\n",
        "                     'potential_option_grade', 'additional_potential_option_grade']\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/item_nomissingvalues_copy.csv')\n",
        "df_stat = pd.read_csv('/content/drive/MyDrive/data/merged/stat_merged.csv')\n",
        "df_stat_trimmed = df_stat[['nickname', 'subclass', 'ì „íˆ¬ë ¥']].drop_duplicates()\n",
        "df = df.merge(df_stat_trimmed, on=['nickname', 'subclass'], how='left')\n",
        "df.dropna(subset=['ì „íˆ¬ë ¥'], inplace=True)\n",
        "\n",
        "# í•„í„°ë§ ë° ì „ì²˜ë¦¬\n",
        "df = df[df['equipment_slot'].isin(selected_slots)].copy()\n",
        "df = df.dropna(subset=selected_features + ['ì „íˆ¬ë ¥'])\n",
        "\n",
        "# í”¼ì²˜ ë¶„ë¦¬\n",
        "cat_cols = ['item_group', 'potential_option_grade', 'additional_potential_option_grade']\n",
        "num_cols = ['starforce', 'mainstat_total', 'power_total']\n",
        "\n",
        "# ì¸ì½”ë”© + ìŠ¤ì¼€ì¼ë§\n",
        "encoders = {col: LabelEncoder().fit(df[col]) for col in cat_cols}\n",
        "for col in cat_cols:\n",
        "    df[col] = encoders[col].transform(df[col])\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "df['log_ì „íˆ¬ë ¥'] = np.log1p(df['ì „íˆ¬ë ¥'])\n",
        "\n",
        "# ì‹œí€€ìŠ¤ êµ¬ì„±\n",
        "max_len = len(selected_slots)\n",
        "df = df.sort_values(\"nickname\")\n",
        "\n",
        "x_cat_list, x_cont_list, mask_list, y_list = [], [], [], []\n",
        "\n",
        "for name, group in df.groupby(\"nickname\"):\n",
        "    cat = group[cat_cols].values.astype(np.int64)\n",
        "    cont = group[num_cols].values.astype(np.float32)\n",
        "    valid_len = len(group)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        pad_cat = np.zeros((max_len - valid_len, len(cat_cols)))\n",
        "        pad_cont = np.zeros((max_len - valid_len, len(num_cols)))\n",
        "        pad_mask = [0] * (max_len - valid_len)\n",
        "        cat = np.vstack([cat, pad_cat])\n",
        "        cont = np.vstack([cont, pad_cont])\n",
        "        mask = [1] * valid_len + pad_mask\n",
        "    else:\n",
        "        cat = cat[:max_len]\n",
        "        cont = cont[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    x_cat_list.append(torch.tensor(cat, dtype=torch.long))\n",
        "    x_cont_list.append(torch.tensor(cont, dtype=torch.float32))\n",
        "    mask_list.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    y_list.append(np.log1p(group['ì „íˆ¬ë ¥'].iloc[0]))\n",
        "\n",
        "x_cat = torch.stack(x_cat_list)\n",
        "x_cont = torch.stack(x_cont_list)\n",
        "mask = torch.stack(mask_list)\n",
        "y = torch.tensor(y_list, dtype=torch.float32)\n",
        "\n",
        "# ì¥ë¹„ ê°œìˆ˜ feature ì¶”ê°€\n",
        "equip_counts = mask.sum(dim=1).unsqueeze(1).repeat(1, x_cont.shape[1]).unsqueeze(2)\n",
        "x_cont = torch.cat([x_cont, equip_counts], dim=2)\n",
        "\n",
        "embedding_info = {col: df[col].nunique() for col in cat_cols}\n",
        "\n",
        "# ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmses, r2s = [], []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(x_cat)):\n",
        "    model = DeepMaskedModel(embedding_info, x_cont.shape[-1])\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    train_set = torch.utils.data.TensorDataset(x_cat[train_idx], x_cont[train_idx], mask[train_idx], y[train_idx])\n",
        "    val_set = torch.utils.data.TensorDataset(x_cat[val_idx], x_cont[val_idx], mask[val_idx], y[val_idx])\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=256)\n",
        "\n",
        "    for epoch in range(5):\n",
        "        model.train()\n",
        "        for xc, xc2, m, yt in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(xc, xc2, m)\n",
        "            loss = criterion(pred, yt)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    preds, targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for xc, xc2, m, yt in val_loader:\n",
        "            pred = model(xc, xc2, m)\n",
        "            preds.append(pred.numpy())\n",
        "            targets.append(yt.numpy())\n",
        "\n",
        "    preds = np.concatenate(preds)\n",
        "    targets = np.concatenate(targets)\n",
        "    rmse = np.sqrt(mean_squared_error(targets, preds))\n",
        "    r2 = r2_score(targets, preds)\n",
        "    rmses.append(rmse)\n",
        "    r2s.append(r2)\n",
        "    print(f\"Fold {fold+1}: RMSE={rmse:.4f}, R2={r2:.4f}\")\n",
        "\n",
        "print(f\"\\nğŸ“Š ìµœì¢… í‰ê·  ì„±ëŠ¥ (7ê°œ ì¥ë¹„ í•µì‹¬ í”¼ì²˜): RMSE={np.mean(rmses):.4f}, R2={np.mean(r2s):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS5wqli7wape",
        "outputId": "a4ddcc4c-d4eb-45d6-c795-a17de55bff56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-101-b03c4d71cc1a>:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = encoders[col].transform(df[col])\n",
            "<ipython-input-101-b03c4d71cc1a>:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = encoders[col].transform(df[col])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: RMSE=0.7845, R2=0.4024\n",
            "Fold 2: RMSE=0.6897, R2=0.5501\n",
            "Fold 3: RMSE=0.6644, R2=0.5335\n",
            "Fold 4: RMSE=0.6826, R2=0.4811\n",
            "Fold 5: RMSE=0.6304, R2=0.5600\n",
            "\n",
            "ğŸ“Š ìµœì¢… í‰ê·  ì„±ëŠ¥ (7ê°œ ì¥ë¹„ í•µì‹¬ í”¼ì²˜): RMSE=0.6903, R2=0.5054\n"
          ]
        }
      ]
    }
  ]
}